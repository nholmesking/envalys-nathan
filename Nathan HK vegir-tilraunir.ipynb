{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb1f41a-1e42-4d6d-bc9c-f9dcd67e2dfa",
   "metadata": {},
   "source": [
    "# Tilraunir fyrir vegagreiningu á gervitunglamyndum\n",
    "Nathan HK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79a1311-7a3d-44c3-8912-8d6052611252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gc\n",
    "from io import BytesIO\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import psutil\n",
    "from pyrosm import OSM\n",
    "from pyrosm import get_data\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from shapely.geometry import Point\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73776003-4532-416f-8943-3f9ea869de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa = '/Users/002-nathan/Desktop/Envalys/gtm/'\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35614a2d-fc85-4085-b036-144f8ce4cbe7",
   "metadata": {},
   "source": [
    "## Inngangsorð\n",
    "Við viljum þjálfa gervigreindarlíkan til að greina vegi á gervitunglamyndum. Við þurfum tvenn gögn: gervitunglamyndir og staðsetningar vega.\n",
    "- **Gervitunglamyndir:** Við notum skjámyndatökur af Já.is. Ég veit ekki hvort þetta sé löglegt, en ég er ekki með neinar betri leiðir.\n",
    "- **Staðsetningar vega:** Við notum OpenStreetMap.\n",
    "\n",
    "Ég nota Apple M1 Pro-örgjörvi með 16 GB minni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ca15a-f705-45bc-a0a4-8c96bcfded27",
   "metadata": {},
   "source": [
    "## Gervitunglamyndir\n",
    "Við notum lista yfir greinar á ensku Wikipediunni um staði á Höfuðborgarsvæðinu og Akureyri. Gögnin á Landsbyggðinni eru ekki nóg nákvæm fyrir þetta líkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611f2f21-144c-4ed2-abb1-c98e8e015757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "hnitlisti = []\n",
    "hnit_sv = {'h':[(64.167, 64.073, -21.649992, -22.041892, 30, 40),\n",
    "                (64.073, 64.033177, -21.871, -22.041892, 20, 20),\n",
    "                (64.200015, 64.167, -21.649992, -21.763, 10, 10)],\n",
    "           'a':[(65.706074, 65.656070, -18.073935, -18.148693, 10, 0)]}\n",
    "for svk in hnit_sv:\n",
    "    for hnit_h in hnit_sv[svk]:\n",
    "        diff = (hnit_h[0] - hnit_h[1], hnit_h[2] - hnit_h[3])\n",
    "        for i in range(hnit_h[4]):\n",
    "            lat = round(hnit_h[1] + (i * 2 + 1) * diff[0] / 60, 6)\n",
    "            for j in range(hnit_h[5]):\n",
    "                lon = round(hnit_h[3] + (j * 2 + 1) * diff[1] / 60, 6)\n",
    "                hnitlisti.append((svk, lat, lon))\n",
    "\n",
    "for a in os.listdir(mappa):\n",
    "    s = a.split('_')\n",
    "    if len(s) != 3 or s[0] not in ['h', 'a', 'r'] or s[2][-4:] != '.png':\n",
    "        continue\n",
    "    tp = (s[0], float(s[1]), float(s[2][:-4]))\n",
    "    if tp not in hnitlisti:\n",
    "        hnitlisti.append(tp)\n",
    "hnitlisti = hnitlisti[:2000]\n",
    "\n",
    "print(len(hnitlisti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9befe0c-77da-4c6c-a169-b550da856dad",
   "metadata": {},
   "source": [
    "Við getum ekki tekið myndir af miðjunni skjásins, því það eru önnur HTML-efni sem hylja gervitunglamyndirnar. Þess vegna leitum við að staði sem eru 0.002° til austurs frá myndatökustaðnum; hérna eru hnitin á skjánum fyrir þennan stað."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027be46b-66c6-413c-b70c-e59611deffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skhn = (746, 861)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7197e-1815-456d-bfd1-fdd04936ba0b",
   "metadata": {},
   "source": [
    "Við tökum skjámyndir af öllum stöðum á hnitlistanum.\n",
    "- URL-ið notar ISN93-hnit, en okkar hnit eru WGS84, og það er engin einföld leið til að skipta milli þeirra. Þess vegna þurfum við að leita að hnitum eins og manneskja myndi leita.\n",
    "- Á Chrome er myndasvæðið 512x512, en þegar myndin er vistuð verður hún 1024x1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b85159f-82ed-4569-b14e-8ce2a6794e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09639310836791992\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "f = False\n",
    "for n in range(len(hnitlisti)):\n",
    "    hnit = hnitlisti[n]\n",
    "    try:\n",
    "        z = open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png', 'rb')\n",
    "        z.close()\n",
    "    except FileNotFoundError:\n",
    "        f = True\n",
    "        break\n",
    "if f:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.set_window_size(1500, 1000)\n",
    "    driver.get('https://ja.is/kort/?x=356954&y=408253&nz=17.00&type=aerialnl')\n",
    "    # Accept GDPR\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, '//a[@id=\"gdpr_banner_ok\"]')\n",
    "        btn.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    # Allow cookies\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, '//button[@class=\"ch2-btn ch2-allow-all-btn ch2-btn-primary\"]')\n",
    "        btn.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    leit = driver.find_element(By.XPATH, '//input[@id=\"mapq\"]')\n",
    "    for n in range(len(hnitlisti)):\n",
    "        if n % 100 == 0:\n",
    "            print(n, time.time() - byrjun)\n",
    "        hnit = hnitlisti[n]\n",
    "        try:\n",
    "            # Does file exist?\n",
    "            z = open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png', 'rb')\n",
    "            z.close()\n",
    "        except FileNotFoundError:\n",
    "            # Input search term into search box\n",
    "            leit.clear()\n",
    "            leit.send_keys(str(hnit[1]) + ', ' + str(hnit[2] + 0.002))\n",
    "            leit.send_keys(Keys.RETURN)\n",
    "            time.sleep(2) # Wait for images to load\n",
    "            try:  # Place not found\n",
    "                nf = driver.find_element(By.XPATH, '//div[@class=\"row not-found\"]')\n",
    "            except NoSuchElementException:  # Place found, save and crop screenshot\n",
    "                driver.save_screenshot(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "                skmynd = Image.open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "                skmynd = skmynd.crop((skhn[0] - 512, skhn[1] - 512, skhn[0] + 512, skhn[1] + 512))\n",
    "                skmynd.save(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "            time.sleep(1)\n",
    "    driver.close()\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4be53-241f-47e9-8bf5-61fbb7134c93",
   "metadata": {},
   "source": [
    "## Staðsetningar vega\n",
    "Við sækjum gögn frá OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a890d29-f591-4459-8221-24fe5601231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_data('Iceland')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec4b6f-00f5-4b0c-a66b-1940697b3d2a",
   "metadata": {},
   "source": [
    "Þetta undirforrit tekur díl á myndinni og finnur GPS-hnitin. Við notum Web Mercator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0536b8-b22f-41ed-9372-7df9a9cfb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix2coord(pix, hnit_br):\n",
    "    x_t = hnit_br[1] + (pix[0] - 512) / 1024\n",
    "    lon = math.degrees(x_t * 2 * math.pi / (2 ** 17) - math.pi)\n",
    "    y_t = hnit_br[0] + (pix[1] - 512) / 1024\n",
    "    lat = math.degrees(2 * (math.atan(math.exp(math.pi - y_t * 2 * math.pi / (2 ** 17))) - math.pi / 4))\n",
    "    return (lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a675895-2250-4bd4-b5fd-56386ec8da38",
   "metadata": {},
   "source": [
    "Þetta undirforrit tekur GPS-hnit og finnur dílinn á myndinni. Forritað með aðstoð frá o1-preview eftir OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35165ce-22f9-4562-a902-22e3249acf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2pix(lat, lon, hnit_br):\n",
    "    # Convert degrees to radians\n",
    "    lon_radians = math.radians(lon)\n",
    "    lat_radians = math.radians(lat)\n",
    "    \n",
    "    # Invert the calculation for x_t\n",
    "    x_t = ((lon_radians + math.pi) * (2 ** 17)) / (2 * math.pi)\n",
    "    # Calculate pix[0] (x-coordinate)\n",
    "    pix_x = (x_t - hnit_br[1]) * 1024 + 512\n",
    "    \n",
    "    # Invert the calculation for y_t\n",
    "    b = lat_radians / 2 + math.pi / 4\n",
    "    a = math.tan(b)\n",
    "    c = math.pi - math.log(a)\n",
    "    y_t = c * (2 ** 17) / (2 * math.pi)\n",
    "    # Calculate pix[1] (y-coordinate)\n",
    "    pix_y = (y_t - hnit_br[0]) * 1024 + 512\n",
    "    \n",
    "    return (pix_x, pix_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eecab4-b5e7-4950-ba40-4764bfe3810e",
   "metadata": {},
   "source": [
    "Við sækjum tvo lista: einn yfir vegi á Höfuðborgarsvæðinu, og einn á Akureyri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0530e148-868a-4de1-8204-d2e3dbd7462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.214306116104126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "veg_listi = {}\n",
    "osm_h = OSM(fp, bounding_box=[-22.140901, 63.847886, -21.152576, 64.390306])\n",
    "veg_listi['h'] = osm_h.get_network(network_type='driving')\n",
    "osm_a = OSM(fp, bounding_box=[-18.398071, 65.543087, -17.968359, 66.576398])\n",
    "veg_listi['a'] = osm_a.get_network(network_type='driving')\n",
    "osm_r = OSM(fp, bounding_box=[-22.735807, 63.883749, -22.359850, 64.090630])\n",
    "veg_listi['r'] = osm_r.get_network(network_type='driving')\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa351946-9653-4f41-8013-8a4b53ff9074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2630190849304199\n",
      "100 29.14673113822937\n",
      "200 57.902225971221924\n",
      "300 87.10287117958069\n",
      "400 116.3566882610321\n",
      "500 145.91966319084167\n",
      "600 175.23962593078613\n",
      "700 204.23475098609924\n",
      "800 233.34452199935913\n",
      "900 262.17678594589233\n",
      "1000 290.9967591762543\n",
      "1100 319.9600729942322\n",
      "1200 348.565810918808\n",
      "1300 377.23442006111145\n",
      "1400 405.57364106178284\n",
      "1500 433.32680010795593\n",
      "1600 460.8351879119873\n",
      "1700 488.47044706344604\n",
      "1800 516.3400180339813\n",
      "1900 544.07088804245\n",
      "571.4813911914825\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "X_gogn = {'R': [], 'G': [], 'B': []}\n",
    "y_gogn = []\n",
    "bd_all = {}\n",
    "for st in ['h', 'a', 'r']:\n",
    "    vegir = veg_listi[st]\n",
    "    bd = []\n",
    "    for k in range(vegir.shape[0]):\n",
    "        bns = vegir['geometry'][k].bounds\n",
    "        bd.append(bns)\n",
    "    bd_all[st] = bd\n",
    "for n in range(len(hnitlisti)):\n",
    "    if n % 100 == 0:\n",
    "        print(n, time.time() - byrjun)\n",
    "    hnit = hnitlisti[n]\n",
    "    \n",
    "    # Open image\n",
    "    try:\n",
    "        gtm = Image.open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "        dilar = gtm.load()\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    except OSError:\n",
    "        print('OSError', hnit)\n",
    "        continue\n",
    "    \n",
    "    # Convert coordinates\n",
    "    y_n = 1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))) - 0.5\n",
    "    y_s = 1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))) + 0.5\n",
    "    if hnit[0] == 'd':\n",
    "        vegir = veg_listi['h']\n",
    "    else:\n",
    "        vegir = veg_listi[hnit[0]]\n",
    "    hnit_br = (1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))),\n",
    "               1 / (2 * math.pi) * 2 ** 17 * (math.pi + math.radians(hnit[2])))\n",
    "    \n",
    "    # Roads\n",
    "    y_mynd = np.zeros((1, 1, 1024, 1024))\n",
    "    if hnit[0] == 'd':\n",
    "        bd = bd_all['h']\n",
    "    else:\n",
    "        bd = bd_all[hnit[0]]\n",
    "    ermedvegi = [0, 0, 0, 0]\n",
    "    for v in range(vegir.shape[0]):\n",
    "        bns = bd[v]\n",
    "        if bns[0] > hnit[2] + 0.0014 or bns[1] > hnit[1] + 0.0008 or bns[2] < hnit[2] - 0.0014 or bns[3] < hnit[1] - 0.0008:\n",
    "            continue\n",
    "        NW = coord2pix(bns[3], bns[0], hnit_br)\n",
    "        SE = coord2pix(bns[1], bns[2], hnit_br)\n",
    "        if NW[0] > 1024 or NW[1] > 1024 or SE[0] < 0 or SE[1] < 0:\n",
    "            continue\n",
    "        for p in vegir.loc[v, 'geometry'].geoms:\n",
    "            x, y = p.xy\n",
    "            if ermedvegi[0] == 1 and y[0] > hnit[1] and x[0] < hnit[2]:\n",
    "                continue\n",
    "            elif ermedvegi[1] == 1 and y[0] > hnit[1] and x[0] > hnit[2]:\n",
    "                continue\n",
    "            elif ermedvegi[2] == 1 and y[0] < hnit[1] and x[0] < hnit[2]:\n",
    "                continue\n",
    "            elif ermedvegi[3] == 1 and y[0] < hnit[1] and x[0] > hnit[2]:\n",
    "                continue\n",
    "            ct = coord2pix(y[0], x[0], hnit_br)\n",
    "            if ct[0] >= 0 and ct[0] < 512 and ct[1] >= 0 and ct[1] < 512:\n",
    "                ermedvegi[0] = 1\n",
    "            elif ct[0] >= 512 and ct[0] < 1024 and ct[1] >= 0 and ct[1] < 512:\n",
    "                ermedvegi[1] = 1\n",
    "            elif ct[0] >= 0 and ct[0] < 512 and ct[1] >= 512 and ct[1] < 1024:\n",
    "                ermedvegi[2] = 1\n",
    "            elif ct[0] >= 512 and ct[0] < 1024 and ct[1] >= 512 and ct[1] < 1024:\n",
    "                ermedvegi[3] = 1\n",
    "        if sum(ermedvegi) == 4:\n",
    "            break\n",
    "    if hnit[0] != 'd':\n",
    "        frummynd = np.array(gtm.getdata()).reshape(1024, 1024, 3)\n",
    "        X_gogn['B'].append(torch.tensor(np.transpose(frummynd[:512, :512, 2:3], (2, 0, 1)).reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn['B'].append(torch.tensor(np.transpose(frummynd[:512, 512:, 2:3], (2, 0, 1)).reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn['B'].append(torch.tensor(np.transpose(frummynd[512:, :512, 2:3], (2, 0, 1)).reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn['B'].append(torch.tensor(np.transpose(frummynd[512:, 512:, 2:3], (2, 0, 1)).reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[0]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[1]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[2]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[3]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "    gtm.close()\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1c583-8900-4bd8-8a8c-ffe2817b22e4",
   "metadata": {},
   "source": [
    "## Líkan\n",
    "Hérna er CNN.\n",
    "\n",
    "Forritað með aðstoð frá o1-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8202373c-2123-4d7d-bed2-f5eb513eb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGLikan(nn.Module):\n",
    "    def __init__(self, ks, p):\n",
    "        super(VGLikan, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)    # Output: 512x512x16\n",
    "        self.pool = nn.MaxPool2d(2, 2)                                       # Output size halved\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)   # Output: 256x256x32\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)   # Output: 128x128x64\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)  # Output: 64x64x128\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 32x32x256\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 16x16x512\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 8x8x512\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 4x4x512\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(2 * 2 * 512, 512, dtype=torch.float16)\n",
    "        self.fc2 = nn.Linear(512, 128, dtype=torch.float16)\n",
    "        self.fc3 = nn.Linear(128, 1, dtype=torch.float16)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch_size, 3, 1024, 1024)\n",
    "        x = F.relu(self.conv1(x))  # Output: (batch_size, 16, 512, 512)\n",
    "        x = self.pool(x)           # Output: (batch_size, 16, 256, 256)\n",
    "\n",
    "        x = F.relu(self.conv2(x))  # Output: (batch_size, 32, 256, 256)\n",
    "        x = self.pool(x)           # Output: (batch_size, 32, 128, 128)\n",
    "\n",
    "        x = F.relu(self.conv3(x))  # Output: (batch_size, 64, 128, 128)\n",
    "        x = self.pool(x)           # Output: (batch_size, 64, 64, 64)\n",
    "\n",
    "        x = F.relu(self.conv4(x))  # Output: (batch_size, 128, 64, 64)\n",
    "        x = self.pool(x)           # Output: (batch_size, 128, 32, 32)\n",
    "\n",
    "        x = F.relu(self.conv5(x))  # Output: (batch_size, 256, 32, 32)\n",
    "        x = self.pool(x)           # Output: (batch_size, 256, 16, 16)\n",
    "\n",
    "        x = F.relu(self.conv6(x))  # Output: (batch_size, 512, 16, 16)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 8, 8)\n",
    "\n",
    "        x = F.relu(self.conv7(x))  # Output: (batch_size, 512, 8, 8)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 4, 4)\n",
    "\n",
    "        x = F.relu(self.conv8(x))  # Output: (batch_size, 512, 4, 4)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 2, 2)\n",
    "\n",
    "        x = x.view(-1, 2 * 2 * 512)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))      # Fully connected layer\n",
    "        x = F.relu(self.fc2(x))      # Fully connected layer\n",
    "        x = self.fc3(x)              # Output layer\n",
    "        x = torch.sigmoid(x)         # Apply sigmoid activation for binary classification\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f84000-11c7-472b-a90f-9ff339a42297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0) False 0 | Time: 123.26162981987\n",
      "(1, 0) False 1 | Time: 236.86027693748474\n",
      "(1, 0) False 2 | Time: 349.7669680118561\n",
      "(1, 0) False 3 | Time: 459.9041998386383\n",
      "(1, 0) False 4 | Time: 569.9441618919373\n",
      "(3, 1) False 0 | Time: 729.8318917751312\n",
      "(3, 1) False 1 | Time: 882.9155659675598\n",
      "(3, 1) False 2 | Time: 1039.062941789627\n",
      "(3, 1) False 3 | Time: 1196.7326698303223\n",
      "(3, 1) False 4 | Time: 1354.8919930458069\n",
      "(5, 2) False 0 | Time: 1688.947411775589\n",
      "(5, 2) False 1 | Time: 2020.557473897934\n",
      "(5, 2) False 2 | Time: 2348.3540546894073\n",
      "(5, 2) False 3 | Time: 2678.913416862488\n",
      "(5, 2) False 4 | Time: 3014.7852289676666\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "outfile = open(mappa + '../envalys-nathan/tilraunir.csv', 'w')\n",
    "ritari = csv.writer(outfile)\n",
    "ritari.writerow(['Kernel size', 'Nesterov', 'Random state', 'Train diff', 'Test diff'])\n",
    "for a in [(1, 0), (3, 1), (5, 2)]:  # Kernel size, padding\n",
    "    for b in [False]:  # Nesterov\n",
    "        for c in range(5):  # Random state\n",
    "            # Initialize model\n",
    "            likan = VGLikan(a[0], a[1]).to(device)\n",
    "            \n",
    "            # Define a loss function and optimizer\n",
    "            criterion = nn.BCELoss()\n",
    "            optimizer = optim.SGD(likan.parameters(), lr=1e-3, momentum=0.25)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_gogn['B'], y_gogn, random_state=c)\n",
    "            \n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "            \n",
    "            likan.eval()\n",
    "            with torch.no_grad():\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_train)):\n",
    "                    y_pred = likan(X_train[i])\n",
    "                    loss = criterion(y_pred, y_train[i])\n",
    "                    rl += loss.item()\n",
    "                train_loss.append(rl / len(X_train))\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_test)):\n",
    "                    y_pred = likan(X_test[i])\n",
    "                    loss = criterion(y_pred, y_test[i])\n",
    "                    rl += loss.item()\n",
    "                test_loss.append(rl / len(X_test))\n",
    "            torch.mps.empty_cache()\n",
    "                \n",
    "            likan.train()\n",
    "            for i in range(len(X_train)):\n",
    "                y_pred = likan(X_train[i])\n",
    "                loss = criterion(y_pred, y_train[i])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                torch.mps.synchronize()\n",
    "                if i % 10 == 0:\n",
    "                    torch.mps.empty_cache()\n",
    "                \n",
    "            torch.mps.empty_cache()\n",
    "            \n",
    "            likan.eval()\n",
    "            with torch.no_grad():\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_train)):\n",
    "                    y_pred = likan(X_train[i])\n",
    "                    loss = criterion(y_pred, y_train[i])\n",
    "                    rl += loss.item()\n",
    "                train_loss.append(rl / len(X_train))\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_test)):\n",
    "                    y_pred = likan(X_test[i])\n",
    "                    loss = criterion(y_pred, y_test[i])\n",
    "                    rl += loss.item()\n",
    "                test_loss.append(rl / len(X_test))\n",
    "            torch.mps.empty_cache()\n",
    "        \n",
    "            # Print loss for the current epoch\n",
    "            print(a, b, c, '| Time:', time.time() - byrjun)\n",
    "\n",
    "            ritari.writerow([a, b, c, train_loss[0] - train_loss[1], test_loss[0] - test_loss[1]])\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532eee4-7f2b-43b8-ae3b-f75f05ba8560",
   "metadata": {},
   "source": [
    "## Lokaorð\n",
    "Þetta líkan er ekki nógu gott. Ég reyndi að þjálfa líkanið með 3.000 myndum, en það var of mikið fyrir tölvuna mína."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54225e83-d1dc-417f-ab31-51a54c3ff6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
