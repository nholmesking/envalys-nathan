{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb1f41a-1e42-4d6d-bc9c-f9dcd67e2dfa",
   "metadata": {},
   "source": [
    "# Vegagreining á gervitunglamyndum (FRUMLÍKAN)\n",
    "Nathan HK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79a1311-7a3d-44c3-8912-8d6052611252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k7/ssgp6zcs72j0lsw27nm39kvw0000gn/T/ipykernel_66871/2527067105.py\", line 11, in <module>\n",
      "    from pyrosm import OSM\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/__init__.py\", line 1, in <module>\n",
      "    from pyrosm.data import get_data, get_path  # drop get_path in the future\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/data/__init__.py\", line 2, in <module>\n",
      "    from pyrosm.utils.download import download\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/utils/__init__.py\", line 8, in <module>\n",
      "    import geopandas as gpd\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/__init__.py\", line 3, in <module>\n",
      "    from geopandas.geoseries import GeoSeries\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geoseries.py\", line 9, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k7/ssgp6zcs72j0lsw27nm39kvw0000gn/T/ipykernel_66871/2527067105.py\", line 11, in <module>\n",
      "    from pyrosm import OSM\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/__init__.py\", line 1, in <module>\n",
      "    from pyrosm.data import get_data, get_path  # drop get_path in the future\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/data/__init__.py\", line 2, in <module>\n",
      "    from pyrosm.utils.download import download\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/utils/__init__.py\", line 8, in <module>\n",
      "    import geopandas as gpd\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/__init__.py\", line 3, in <module>\n",
      "    from geopandas.geoseries import GeoSeries\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geoseries.py\", line 9, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gc\n",
    "from io import BytesIO\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import psutil\n",
    "from pyrosm import OSM\n",
    "from pyrosm import get_data\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from shapely.geometry import Point\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73776003-4532-416f-8943-3f9ea869de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa = '/Users/002-nathan/Desktop/Envalys/gtm/'\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35614a2d-fc85-4085-b036-144f8ce4cbe7",
   "metadata": {},
   "source": [
    "## Inngangsorð\n",
    "Við viljum þjálfa gervigreindarlíkan til að greina vegi á gervitunglamyndum. Við þurfum tvenn gögn: gervitunglamyndir og staðsetningar vega.\n",
    "- **Gervitunglamyndir:** Við notum skjámyndatökur af Já.is. Ég veit ekki hvort þetta sé löglegt, en ég er ekki með neinar betri leiðir.\n",
    "- **Staðsetningar vega:** Við notum OpenStreetMap.\n",
    "\n",
    "Ég nota Apple M1 Pro-örgjörvi með 16 GB minni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ca15a-f705-45bc-a0a4-8c96bcfded27",
   "metadata": {},
   "source": [
    "## Gervitunglamyndir\n",
    "Við notum lista yfir greinar á ensku Wikipediunni um staði á Höfuðborgarsvæðinu og Akureyri. Gögnin á Landsbyggðinni eru ekki nóg nákvæm fyrir þetta líkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611f2f21-144c-4ed2-abb1-c98e8e015757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "hnitlisti = []\n",
    "hnit_sv = {'h':[(64.167, 64.073, -21.649992, -22.041892, 30, 40),\n",
    "                (64.073, 64.033177, -21.871, -22.041892, 20, 20),\n",
    "                (64.200015, 64.167, -21.649992, -21.763, 10, 10)],\n",
    "           'a':[(65.706074, 65.656070, -18.073935, -18.148693, 10, 10)]}\n",
    "for svk in hnit_sv:\n",
    "    for hnit_h in hnit_sv[svk]:\n",
    "        diff = (hnit_h[0] - hnit_h[1], hnit_h[2] - hnit_h[3])\n",
    "        for i in range(hnit_h[4]):\n",
    "            lat = round(hnit_h[1] + (i * 2 + 1) * diff[0] / 60, 6)\n",
    "            for j in range(hnit_h[5]):\n",
    "                lon = round(hnit_h[3] + (j * 2 + 1) * diff[1] / 60, 6)\n",
    "                hnitlisti.append((svk, lat, lon))\n",
    "\n",
    "for a in os.listdir(mappa):\n",
    "    s = a.split('_')\n",
    "    if len(s) != 3 or s[0] not in ['h', 'a', 'd'] or s[2][-4:] != '.png':\n",
    "        continue\n",
    "    tp = (s[0], float(s[1]), float(s[2][:-4]))\n",
    "    if tp not in hnitlisti:\n",
    "        hnitlisti.append(tp)\n",
    "hnitlisti = hnitlisti[:2000]\n",
    "\n",
    "print(len(hnitlisti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9befe0c-77da-4c6c-a169-b550da856dad",
   "metadata": {},
   "source": [
    "Við getum ekki tekið myndir af miðjunni skjásins, því það eru önnur HTML-efni sem hylja gervitunglamyndirnar. Þess vegna leitum við að staði sem eru 0.002° til austurs frá myndatökustaðnum; hérna eru hnitin á skjánum fyrir þennan stað."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027be46b-66c6-413c-b70c-e59611deffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skhn = (746, 861)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7197e-1815-456d-bfd1-fdd04936ba0b",
   "metadata": {},
   "source": [
    "Við tökum skjámyndir af öllum stöðum á hnitlistanum.\n",
    "- URL-ið notar ISN93-hnit, en okkar hnit eru WGS84, og það er engin einföld leið til að skipta milli þeirra. Þess vegna þurfum við að leita að hnitum eins og manneskja myndi leita.\n",
    "- Á Chrome er myndasvæðið 512x512, en þegar myndin er vistuð verður hún 1024x1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b85159f-82ed-4569-b14e-8ce2a6794e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04845285415649414\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "f = False\n",
    "for n in range(len(hnitlisti)):\n",
    "    hnit = hnitlisti[n]\n",
    "    try:\n",
    "        z = open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png', 'rb')\n",
    "        z.close()\n",
    "    except FileNotFoundError:\n",
    "        f = True\n",
    "        break\n",
    "if f:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.set_window_size(1500, 1000)\n",
    "    driver.get('https://ja.is/kort/?x=356954&y=408253&nz=17.00&type=aerialnl')\n",
    "    # Accept GDPR\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, '//a[@id=\"gdpr_banner_ok\"]')\n",
    "        btn.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    # Allow cookies\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, '//button[@class=\"ch2-btn ch2-allow-all-btn ch2-btn-primary\"]')\n",
    "        btn.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    leit = driver.find_element(By.XPATH, '//input[@id=\"mapq\"]')\n",
    "    for n in range(len(hnitlisti)):\n",
    "        if n % 100 == 0:\n",
    "            print(n, time.time() - byrjun)\n",
    "        hnit = hnitlisti[n]\n",
    "        try:\n",
    "            # Does file exist?\n",
    "            z = open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png', 'rb')\n",
    "            z.close()\n",
    "        except FileNotFoundError:\n",
    "            # Input search term into search box\n",
    "            leit.clear()\n",
    "            leit.send_keys(str(hnit[1]) + ', ' + str(hnit[2] + 0.002))\n",
    "            leit.send_keys(Keys.RETURN)\n",
    "            time.sleep(2) # Wait for images to load\n",
    "            try:  # Place not found\n",
    "                nf = driver.find_element(By.XPATH, '//div[@class=\"row not-found\"]')\n",
    "            except NoSuchElementException:  # Place found, save and crop screenshot\n",
    "                driver.save_screenshot(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "                skmynd = Image.open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "                skmynd = skmynd.crop((skhn[0] - 512, skhn[1] - 512, skhn[0] + 512, skhn[1] + 512))\n",
    "                skmynd.save(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "            time.sleep(1)\n",
    "    driver.close()\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4be53-241f-47e9-8bf5-61fbb7134c93",
   "metadata": {},
   "source": [
    "## Staðsetningar vega\n",
    "Við sækjum gögn frá OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a890d29-f591-4459-8221-24fe5601231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_data('Iceland')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec4b6f-00f5-4b0c-a66b-1940697b3d2a",
   "metadata": {},
   "source": [
    "Þetta undirforrit tekur díl á myndinni og finnur GPS-hnitin. Við notum Web Mercator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0536b8-b22f-41ed-9372-7df9a9cfb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix2coord(pix, hnit_br):\n",
    "    x_t = hnit_br[1] + (pix[0] - 512) / 1024\n",
    "    lon = math.degrees(x_t * 2 * math.pi / (2 ** 17) - math.pi)\n",
    "    y_t = hnit_br[0] + (pix[1] - 512) / 1024\n",
    "    lat = math.degrees(2 * (math.atan(math.exp(math.pi - y_t * 2 * math.pi / (2 ** 17))) - math.pi / 4))\n",
    "    return (lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a675895-2250-4bd4-b5fd-56386ec8da38",
   "metadata": {},
   "source": [
    "Þetta undirforrit tekur GPS-hnit og finnur dílinn á myndinni. Forritað með aðstoð frá o1-preview eftir OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35165ce-22f9-4562-a902-22e3249acf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2pix(lat, lon, hnit_br):\n",
    "    # Convert degrees to radians\n",
    "    lon_radians = math.radians(lon)\n",
    "    lat_radians = math.radians(lat)\n",
    "    \n",
    "    # Invert the calculation for x_t\n",
    "    x_t = ((lon_radians + math.pi) * (2 ** 17)) / (2 * math.pi)\n",
    "    # Calculate pix[0] (x-coordinate)\n",
    "    pix_x = (x_t - hnit_br[1]) * 1024 + 512\n",
    "    \n",
    "    # Invert the calculation for y_t\n",
    "    b = lat_radians / 2 + math.pi / 4\n",
    "    a = math.tan(b)\n",
    "    c = math.pi - math.log(a)\n",
    "    y_t = c * (2 ** 17) / (2 * math.pi)\n",
    "    # Calculate pix[1] (y-coordinate)\n",
    "    pix_y = (y_t - hnit_br[0]) * 1024 + 512\n",
    "    \n",
    "    return (pix_x, pix_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eecab4-b5e7-4950-ba40-4764bfe3810e",
   "metadata": {},
   "source": [
    "Við sækjum tvo lista: einn yfir vegi á Höfuðborgarsvæðinu, og einn á Akureyri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0530e148-868a-4de1-8204-d2e3dbd7462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.416412830352783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "veg_listi = {}\n",
    "osm_h = OSM(fp, bounding_box=[-22.140901, 63.847886, -21.152576, 64.390306])\n",
    "veg_listi['h'] = osm_h.get_network(network_type='driving')\n",
    "osm_a = OSM(fp, bounding_box=[-18.398071, 65.543087, -17.968359, 66.576398])\n",
    "veg_listi['a'] = osm_a.get_network(network_type='driving')\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa351946-9653-4f41-8013-8a4b53ff9074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.26480722427368164\n",
      "100 26.587915182113647\n",
      "200 52.78448939323425\n",
      "300 78.78109121322632\n",
      "400 104.78092217445374\n",
      "500 131.21560716629028\n",
      "600 157.54916715621948\n",
      "700 183.8770842552185\n",
      "800 209.76988315582275\n",
      "900 235.4645881652832\n",
      "1000 261.4184203147888\n",
      "1100 287.2537832260132\n",
      "1200 313.35074830055237\n",
      "1300 340.0909082889557\n",
      "1400 366.3299071788788\n",
      "1500 392.19038820266724\n",
      "1600 418.11995816230774\n",
      "1700 443.74422121047974\n",
      "1800 469.61511611938477\n",
      "1900 495.4584970474243\n",
      "521.3652181625366\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "X_gogn = []\n",
    "y_gogn = []\n",
    "bd_all = {}\n",
    "for st in ['h', 'a']:\n",
    "    vegir = veg_listi[st]\n",
    "    bd = []\n",
    "    for k in range(vegir.shape[0]):\n",
    "        bns = vegir['geometry'][k].bounds\n",
    "        bd.append(bns)\n",
    "    bd_all[st] = bd\n",
    "for n in range(len(hnitlisti)):\n",
    "    if n % 100 == 0:\n",
    "        print(n, time.time() - byrjun)\n",
    "    hnit = hnitlisti[n]\n",
    "    \n",
    "    # Open image\n",
    "    try:\n",
    "        gtm = Image.open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "        dilar = gtm.load()\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    except OSError:\n",
    "        print('OSError', hnit)\n",
    "        continue\n",
    "    \n",
    "    # Convert coordinates\n",
    "    y_n = 1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))) - 0.5\n",
    "    y_s = 1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))) + 0.5\n",
    "    if hnit[0] == 'd':\n",
    "        vegir = veg_listi['h']\n",
    "    else:\n",
    "        vegir = veg_listi[hnit[0]]\n",
    "    hnit_br = (1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))),\n",
    "               1 / (2 * math.pi) * 2 ** 17 * (math.pi + math.radians(hnit[2])))\n",
    "    \n",
    "    # Roads\n",
    "    y_mynd = np.zeros((1, 1, 1024, 1024))\n",
    "    if hnit[0] == 'd':\n",
    "        bd = bd_all['h']\n",
    "    else:\n",
    "        bd = bd_all[hnit[0]]\n",
    "    ermedvegi = [0, 0, 0, 0]\n",
    "    for v in range(vegir.shape[0]):\n",
    "        bns = bd[v]\n",
    "        if bns[0] > hnit[2] + 0.0014 or bns[1] > hnit[1] + 0.0008 or bns[2] < hnit[2] - 0.0014 or bns[3] < hnit[1] - 0.0008:\n",
    "            continue\n",
    "        NW = coord2pix(bns[3], bns[0], hnit_br)\n",
    "        SE = coord2pix(bns[1], bns[2], hnit_br)\n",
    "        if NW[0] > 1024 or NW[1] > 1024 or SE[0] < 0 or SE[1] < 0:\n",
    "            continue\n",
    "        for p in vegir.loc[v, 'geometry'].geoms:\n",
    "            x, y = p.xy\n",
    "            if ermedvegi[0] == 1 and y[0] > hnit[1] and x[0] < hnit[2]:\n",
    "                continue\n",
    "            elif ermedvegi[1] == 1 and y[0] > hnit[1] and x[0] > hnit[2]:\n",
    "                continue\n",
    "            elif ermedvegi[2] == 1 and y[0] < hnit[1] and x[0] < hnit[2]:\n",
    "                continue\n",
    "            elif ermedvegi[3] == 1 and y[0] < hnit[1] and x[0] > hnit[2]:\n",
    "                continue\n",
    "            ct = coord2pix(y[0], x[0], hnit_br)\n",
    "            if ct[0] >= 0 and ct[0] < 512 and ct[1] >= 0 and ct[1] < 512:\n",
    "                ermedvegi[0] = 1\n",
    "            elif ct[0] >= 512 and ct[0] < 1024 and ct[1] >= 0 and ct[1] < 512:\n",
    "                ermedvegi[1] = 1\n",
    "            elif ct[0] >= 0 and ct[0] < 512 and ct[1] >= 512 and ct[1] < 1024:\n",
    "                ermedvegi[2] = 1\n",
    "            elif ct[0] >= 512 and ct[0] < 1024 and ct[1] >= 512 and ct[1] < 1024:\n",
    "                ermedvegi[3] = 1\n",
    "        if sum(ermedvegi) == 4:\n",
    "            break\n",
    "    if hnit[0] != 'd':\n",
    "        frummynd = np.array(gtm.getdata()).reshape(1024, 1024, 3)\n",
    "        X_gogn.append(torch.tensor(np.transpose(frummynd[:512, :512, :], (2, 0, 1)).reshape(1, 3, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn.append(torch.tensor(np.transpose(frummynd[:512, 512:, :], (2, 0, 1)).reshape(1, 3, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn.append(torch.tensor(np.transpose(frummynd[512:, :512, :], (2, 0, 1)).reshape(1, 3, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn.append(torch.tensor(np.transpose(frummynd[512:, 512:, :], (2, 0, 1)).reshape(1, 3, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[0]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[1]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[2]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[3]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "    gtm.close()\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1c583-8900-4bd8-8a8c-ffe2817b22e4",
   "metadata": {},
   "source": [
    "## Líkan\n",
    "Hérna er CNN.\n",
    "\n",
    "Forritað með aðstoð frá o1-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8202373c-2123-4d7d-bed2-f5eb513eb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGLikan(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGLikan, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, dtype=torch.float16)    # Output: 512x512x16\n",
    "        self.pool = nn.MaxPool2d(2, 2)                                       # Output size halved\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, dtype=torch.float16)   # Output: 256x256x32\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, dtype=torch.float16)   # Output: 128x128x64\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, dtype=torch.float16)  # Output: 64x64x128\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, dtype=torch.float16) # Output: 32x32x256\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, dtype=torch.float16) # Output: 16x16x512\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dtype=torch.float16) # Output: 8x8x512\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, dtype=torch.float16) # Output: 4x4x512\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(2 * 2 * 512, 512, dtype=torch.float16)\n",
    "        self.fc2 = nn.Linear(512, 128, dtype=torch.float16)\n",
    "        self.fc3 = nn.Linear(128, 1, dtype=torch.float16)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch_size, 3, 1024, 1024)\n",
    "        x = F.relu(self.conv1(x))  # Output: (batch_size, 16, 512, 512)\n",
    "        x = self.pool(x)           # Output: (batch_size, 16, 256, 256)\n",
    "\n",
    "        x = F.relu(self.conv2(x))  # Output: (batch_size, 32, 256, 256)\n",
    "        x = self.pool(x)           # Output: (batch_size, 32, 128, 128)\n",
    "\n",
    "        x = F.relu(self.conv3(x))  # Output: (batch_size, 64, 128, 128)\n",
    "        x = self.pool(x)           # Output: (batch_size, 64, 64, 64)\n",
    "\n",
    "        x = F.relu(self.conv4(x))  # Output: (batch_size, 128, 64, 64)\n",
    "        x = self.pool(x)           # Output: (batch_size, 128, 32, 32)\n",
    "\n",
    "        x = F.relu(self.conv5(x))  # Output: (batch_size, 256, 32, 32)\n",
    "        x = self.pool(x)           # Output: (batch_size, 256, 16, 16)\n",
    "\n",
    "        x = F.relu(self.conv6(x))  # Output: (batch_size, 512, 16, 16)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 8, 8)\n",
    "\n",
    "        x = F.relu(self.conv7(x))  # Output: (batch_size, 512, 8, 8)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 4, 4)\n",
    "\n",
    "        x = F.relu(self.conv8(x))  # Output: (batch_size, 512, 4, 4)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 2, 2)\n",
    "\n",
    "        x = x.view(-1, 2 * 2 * 512)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))      # Fully connected layer\n",
    "        x = F.relu(self.fc2(x))      # Fully connected layer\n",
    "        x = self.fc3(x)              # Output layer\n",
    "        x = torch.sigmoid(x)         # Apply sigmoid activation for binary classification\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f84000-11c7-472b-a90f-9ff339a42297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam 0.01 0 | Time: 947.8244571685791\n",
      "Adam 0.01 1 | Time: 1868.5105340480804\n",
      "Adam 0.01 2 | Time: 2765.5018980503082\n",
      "Adam 0.01 3 | Time: 3652.451303243637\n",
      "Adam 0.01 4 | Time: 4589.618504285812\n",
      "Adam 0.001 0 | Time: 5511.859539270401\n",
      "Adam 0.001 1 | Time: 6401.188179254532\n",
      "Adam 0.001 2 | Time: 7267.151699066162\n",
      "Adam 0.001 3 | Time: 8185.863275051117\n",
      "Adam 0.001 4 | Time: 9076.810631036758\n",
      "Adam 0.0001 0 | Time: 9956.604474067688\n",
      "Adam 0.0001 1 | Time: 10803.665595054626\n",
      "Adam 0.0001 2 | Time: 11673.726477146149\n",
      "Adam 0.0001 3 | Time: 12590.248419046402\n",
      "Adam 0.0001 4 | Time: 13516.616446256638\n",
      "Adam 1e-05 0 | Time: 14403.217577934265\n",
      "Adam 1e-05 1 | Time: 15272.118499994278\n",
      "Adam 1e-05 2 | Time: 16093.519032001495\n",
      "Adam 1e-05 3 | Time: 16926.603748083115\n",
      "Adam 1e-05 4 | Time: 17825.068900108337\n",
      "SGD 0.01 0 | Time: 18720.990432024002\n",
      "SGD 0.01 1 | Time: 19611.846498012543\n",
      "SGD 0.01 2 | Time: 20430.19794511795\n",
      "SGD 0.01 3 | Time: 21331.235873937607\n",
      "SGD 0.01 4 | Time: 22203.668865919113\n",
      "SGD 0.001 0 | Time: 23101.100519180298\n",
      "SGD 0.001 1 | Time: 23953.28924894333\n",
      "SGD 0.001 2 | Time: 24825.21850323677\n",
      "SGD 0.001 3 | Time: 25684.224236011505\n",
      "SGD 0.001 4 | Time: 26553.423039913177\n",
      "SGD 0.0001 0 | Time: 27405.933537960052\n",
      "SGD 0.0001 1 | Time: 28248.160540103912\n",
      "SGD 0.0001 2 | Time: 29125.509714126587\n",
      "SGD 0.0001 3 | Time: 29995.8157889843\n",
      "SGD 0.0001 4 | Time: 30884.459910154343\n",
      "SGD 1e-05 0 | Time: 31746.514729976654\n",
      "SGD 1e-05 1 | Time: 32570.203825235367\n",
      "SGD 1e-05 2 | Time: 33428.54609704018\n",
      "SGD 1e-05 3 | Time: 34289.603905916214\n",
      "SGD 1e-05 4 | Time: 35128.29065108299\n",
      "RMSprop 0.01 0 | Time: 36015.45438885689\n",
      "RMSprop 0.01 1 | Time: 36878.81700921059\n",
      "RMSprop 0.01 2 | Time: 37762.541669130325\n",
      "RMSprop 0.01 3 | Time: 38594.75499200821\n",
      "RMSprop 0.01 4 | Time: 39479.333168029785\n",
      "RMSprop 0.001 0 | Time: 40387.33106088638\n",
      "RMSprop 0.001 1 | Time: 41228.10144519806\n",
      "RMSprop 0.001 2 | Time: 42081.32793593407\n",
      "RMSprop 0.001 3 | Time: 42962.67031598091\n",
      "RMSprop 0.001 4 | Time: 43818.79909801483\n",
      "RMSprop 0.0001 0 | Time: 44698.80984711647\n",
      "RMSprop 0.0001 1 | Time: 45535.48768401146\n",
      "RMSprop 0.0001 2 | Time: 46394.42571425438\n",
      "RMSprop 0.0001 3 | Time: 47278.556149959564\n",
      "RMSprop 0.0001 4 | Time: 48149.964405059814\n",
      "RMSprop 1e-05 0 | Time: 49041.124761104584\n",
      "RMSprop 1e-05 1 | Time: 49911.57992315292\n",
      "RMSprop 1e-05 2 | Time: 50777.05017709732\n",
      "RMSprop 1e-05 3 | Time: 51668.08678007126\n",
      "RMSprop 1e-05 4 | Time: 52584.30821609497\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "outfile = open(mappa + '../envalys-nathan/tilraunir.csv', 'w')\n",
    "ritari = csv.writer(outfile)\n",
    "ritari.writerow(['Optimizer', 'Learning rate', 'Random state', 'Train diff', 'Test diff'])\n",
    "for a in ['Adam', 'SGD', 'RMSprop']:  # Optimizer\n",
    "    for b in [1e-2, 1e-3, 1e-4, 1e-5]:  # Learning rate\n",
    "        for c in range(5):  # Random state\n",
    "            # Initialize model\n",
    "            likan = VGLikan().to(device)\n",
    "            \n",
    "            # Define a loss function and optimizer\n",
    "            criterion = nn.BCELoss()\n",
    "            if a == 'Adam':\n",
    "                optimizer = optim.Adam(likan.parameters(), lr=b)\n",
    "            elif a == 'SGD':\n",
    "                optimizer = optim.SGD(likan.parameters(), lr=b)\n",
    "            elif a == 'RMSprop':\n",
    "                optimizer = optim.RMSprop(likan.parameters(), lr=b)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_gogn, y_gogn, random_state=c)\n",
    "            \n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "            \n",
    "            likan.eval()\n",
    "            with torch.no_grad():\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_train)):\n",
    "                    y_pred = likan(X_train[i])\n",
    "                    loss = criterion(y_pred, y_train[i])\n",
    "                    rl += loss.item()\n",
    "                train_loss.append(rl / len(X_train))\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_test)):\n",
    "                    y_pred = likan(X_test[i])\n",
    "                    loss = criterion(y_pred, y_test[i])\n",
    "                    rl += loss.item()\n",
    "                test_loss.append(rl / len(X_test))\n",
    "            torch.mps.empty_cache()\n",
    "                \n",
    "            likan.train()\n",
    "            for i in range(len(X_train)):\n",
    "                y_pred = likan(X_train[i])\n",
    "                loss = criterion(y_pred, y_train[i])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                torch.mps.synchronize()\n",
    "                if i % 10 == 0:\n",
    "                    torch.mps.empty_cache()\n",
    "                \n",
    "            torch.mps.empty_cache()\n",
    "            \n",
    "            likan.eval()\n",
    "            with torch.no_grad():\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_train)):\n",
    "                    y_pred = likan(X_train[i])\n",
    "                    loss = criterion(y_pred, y_train[i])\n",
    "                    rl += loss.item()\n",
    "                train_loss.append(rl / len(X_train))\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_test)):\n",
    "                    y_pred = likan(X_test[i])\n",
    "                    loss = criterion(y_pred, y_test[i])\n",
    "                    rl += loss.item()\n",
    "                test_loss.append(rl / len(X_test))\n",
    "            torch.mps.empty_cache()\n",
    "        \n",
    "            # Print loss for the current epoch\n",
    "            print(a, b, c, '| Time:', time.time() - byrjun)\n",
    "\n",
    "            ritari.writerow([a, b, c, train_loss[0] - train_loss[1], test_loss[0] - test_loss[1]])\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532eee4-7f2b-43b8-ae3b-f75f05ba8560",
   "metadata": {},
   "source": [
    "## Lokaorð\n",
    "Þetta líkan er ekki nógu gott. Ég reyndi að þjálfa líkanið með 3.000 myndum, en það var of mikið fyrir tölvuna mína."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
