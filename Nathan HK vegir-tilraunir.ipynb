{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb1f41a-1e42-4d6d-bc9c-f9dcd67e2dfa",
   "metadata": {},
   "source": [
    "# Tilraunir fyrir vegagreiningu á gervitunglamyndum\n",
    "Nathan HK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79a1311-7a3d-44c3-8912-8d6052611252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gc\n",
    "from io import BytesIO\n",
    "import json\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import psutil\n",
    "from pyrosm import OSM\n",
    "from pyrosm import get_data\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from shapely.geometry import Point\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73776003-4532-416f-8943-3f9ea869de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa = '/Users/002-nathan/Desktop/Envalys/gtm/'\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35614a2d-fc85-4085-b036-144f8ce4cbe7",
   "metadata": {},
   "source": [
    "## Inngangsorð\n",
    "Við viljum þjálfa gervigreindarlíkan til að greina vegi á gervitunglamyndum. Við þurfum tvenn gögn: gervitunglamyndir og staðsetningar vega.\n",
    "- **Gervitunglamyndir:** Við notum skjámyndatökur af Já.is. Ég veit ekki hvort þetta sé löglegt, en ég er ekki með neinar betri leiðir.\n",
    "- **Staðsetningar vega:** Við notum OpenStreetMap.\n",
    "\n",
    "Ég nota Apple M1 Pro-örgjörvi með 16 GB minni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ca15a-f705-45bc-a0a4-8c96bcfded27",
   "metadata": {},
   "source": [
    "## Járnbrá\n",
    "Við notum lista yfir greinar á ensku Wikipediunni um staði á Höfuðborgarsvæðinu og Akureyri. Gögnin á Landsbyggðinni eru ekki nóg nákvæm fyrir þetta líkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611f2f21-144c-4ed2-abb1-c98e8e015757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6087\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "hnitlisti = []\n",
    "hnit_sv = {'h':[(64.167, 64.073, -21.649992, -22.041892, 40, 55),\n",
    "                (64.073, 64.033177, -21.871, -22.041892, 20, 20),\n",
    "                (64.200015, 64.167, -21.649992, -21.763, 10, 10)],\n",
    "           'a':[(65.706074, 65.656070, -18.073935, -18.148693, 15, 15)],\n",
    "           'r':[(64.030207, 63.954029, -22.467779, -22.592190, 15, 15)]}\n",
    "for svk in hnit_sv:\n",
    "    for hnit_h in hnit_sv[svk]:\n",
    "        diff = (hnit_h[0] - hnit_h[1], hnit_h[2] - hnit_h[3])\n",
    "        for i in range(hnit_h[4]):\n",
    "            lat = round(hnit_h[1] + (i * 2 + 1) * diff[0] / (hnit_h[4] * 2), 6)\n",
    "            for j in range(hnit_h[5]):\n",
    "                lon = round(hnit_h[3] + (j * 2 + 1) * diff[1] / (hnit_h[5] * 2), 6)\n",
    "                hnitlisti.append((svk, lat, lon))\n",
    "\n",
    "for a in os.listdir(mappa):\n",
    "    s = a.split('_')\n",
    "    if len(s) != 3 or s[0] not in ['h', 'a', 'r'] or s[2][-4:] != '.png':\n",
    "        continue\n",
    "    tp = (s[0], float(s[1]), float(s[2][:-4]))\n",
    "    if tp not in hnitlisti:\n",
    "        hnitlisti.append(tp)\n",
    "\n",
    "print(len(hnitlisti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9befe0c-77da-4c6c-a169-b550da856dad",
   "metadata": {},
   "source": [
    "Við getum ekki tekið myndir af miðjunni skjásins, því það eru önnur HTML-efni sem hylja gervitunglamyndirnar. Þess vegna leitum við að staði sem eru 0.002° til austurs frá myndatökustaðnum; hérna eru hnitin á skjánum fyrir þennan stað."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027be46b-66c6-413c-b70c-e59611deffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skhn = (746, 861)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7197e-1815-456d-bfd1-fdd04936ba0b",
   "metadata": {},
   "source": [
    "Við tökum skjámyndir af öllum stöðum á hnitlistanum.\n",
    "- URL-ið notar ISN93-hnit, en okkar hnit eru WGS84, og það er engin einföld leið til að skipta milli þeirra. Þess vegna þurfum við að leita að hnitum eins og manneskja myndi leita.\n",
    "- Á Chrome er myndasvæðið 512x512, en þegar myndin er vistuð verður hún 1024x1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b85159f-82ed-4569-b14e-8ce2a6794e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17579126358032227\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "f = False\n",
    "for n in range(len(hnitlisti)):\n",
    "    hnit = hnitlisti[n]\n",
    "    try:\n",
    "        z = open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png', 'rb')\n",
    "        z.close()\n",
    "    except FileNotFoundError:\n",
    "        f = True\n",
    "        break\n",
    "if f:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.set_window_size(1500, 1000)\n",
    "    driver.get('https://ja.is/kort/?x=356954&y=408253&nz=17.00&type=aerialnl')\n",
    "    # Accept GDPR\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, '//a[@id=\"gdpr_banner_ok\"]')\n",
    "        btn.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    # Allow cookies\n",
    "    try:\n",
    "        btn = driver.find_element(By.XPATH, '//button[@class=\"ch2-btn ch2-allow-all-btn ch2-btn-primary\"]')\n",
    "        btn.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    leit = driver.find_element(By.XPATH, '//input[@id=\"mapq\"]')\n",
    "    for n in range(len(hnitlisti)):\n",
    "        if n % 100 == 0:\n",
    "            print(n, time.time() - byrjun)\n",
    "        hnit = hnitlisti[n]\n",
    "        try:\n",
    "            # Does file exist?\n",
    "            z = open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png', 'rb')\n",
    "            z.close()\n",
    "        except FileNotFoundError:\n",
    "            # Input search term into search box\n",
    "            leit.clear()\n",
    "            leit.send_keys(str(hnit[1]) + ', ' + str(hnit[2] + 0.002))\n",
    "            leit.send_keys(Keys.RETURN)\n",
    "            time.sleep(2) # Wait for images to load\n",
    "            try:  # Place not found\n",
    "                nf = driver.find_element(By.XPATH, '//div[@class=\"row not-found\"]')\n",
    "            except NoSuchElementException:  # Place found, save and crop screenshot\n",
    "                driver.save_screenshot(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "                skmynd = Image.open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "                skmynd = skmynd.crop((skhn[0] - 512, skhn[1] - 512, skhn[0] + 512, skhn[1] + 512))\n",
    "                skmynd.save(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "            time.sleep(1)\n",
    "    driver.close()\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4be53-241f-47e9-8bf5-61fbb7134c93",
   "metadata": {},
   "source": [
    "## Landbjartur\n",
    "Við sækjum gögn frá OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a890d29-f591-4459-8221-24fe5601231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_data('Iceland')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec4b6f-00f5-4b0c-a66b-1940697b3d2a",
   "metadata": {},
   "source": [
    "Þetta undirforrit tekur díl á myndinni og finnur GPS-hnitin. Við notum Web Mercator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0536b8-b22f-41ed-9372-7df9a9cfb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix2coord(pix, hnit_br):\n",
    "    x_t = hnit_br[1] + (pix[0] - 512) / 1024\n",
    "    lon = math.degrees(x_t * 2 * math.pi / (2 ** 17) - math.pi)\n",
    "    y_t = hnit_br[0] + (pix[1] - 512) / 1024\n",
    "    lat = math.degrees(2 * (math.atan(math.exp(math.pi - y_t * 2 * math.pi / (2 ** 17))) - math.pi / 4))\n",
    "    return (lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a675895-2250-4bd4-b5fd-56386ec8da38",
   "metadata": {},
   "source": [
    "Þetta undirforrit tekur GPS-hnit og finnur dílinn á myndinni. Forritað með aðstoð frá o1-preview eftir OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35165ce-22f9-4562-a902-22e3249acf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord2pix(lat, lon, hnit_br):\n",
    "    # Convert degrees to radians\n",
    "    lon_radians = math.radians(lon)\n",
    "    lat_radians = math.radians(lat)\n",
    "    \n",
    "    # Invert the calculation for x_t\n",
    "    x_t = ((lon_radians + math.pi) * (2 ** 17)) / (2 * math.pi)\n",
    "    # Calculate pix[0] (x-coordinate)\n",
    "    pix_x = (x_t - hnit_br[1]) * 1024 + 512\n",
    "    \n",
    "    # Invert the calculation for y_t\n",
    "    b = lat_radians / 2 + math.pi / 4\n",
    "    a = math.tan(b)\n",
    "    c = math.pi - math.log(a)\n",
    "    y_t = c * (2 ** 17) / (2 * math.pi)\n",
    "    # Calculate pix[1] (y-coordinate)\n",
    "    pix_y = (y_t - hnit_br[0]) * 1024 + 512\n",
    "    \n",
    "    return (pix_x, pix_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eecab4-b5e7-4950-ba40-4764bfe3810e",
   "metadata": {},
   "source": [
    "Við sækjum tvo lista: einn yfir vegi á Höfuðborgarsvæðinu, og einn á Akureyri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0530e148-868a-4de1-8204-d2e3dbd7462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.73022794723511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyrosm/networks.py:37: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges, nodes = prepare_geodataframe(\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "veg_listi = {}\n",
    "osm_h = OSM(fp, bounding_box=[-22.140901, 63.847886, -21.152576, 64.390306])\n",
    "veg_listi['h'] = osm_h.get_network(network_type='driving')\n",
    "osm_a = OSM(fp, bounding_box=[-18.398071, 65.543087, -17.968359, 66.576398])\n",
    "veg_listi['a'] = osm_a.get_network(network_type='driving')\n",
    "osm_r = OSM(fp, bounding_box=[-22.735807, 63.883749, -22.359850, 64.090630])\n",
    "veg_listi['r'] = osm_r.get_network(network_type='driving')\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3bc63cc-a4c0-4f1a-9836-61a8aed4a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    jsonf = open(mappa + 'vegir.json', 'r')\n",
    "    vegir_json = json.load(jsonf)\n",
    "    jsonf.close()\n",
    "except FileNotFoundError:\n",
    "    vegir_json = {}\n",
    "except json.JSONDecodeError:\n",
    "    vegir_json = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa351946-9653-4f41-8013-8a4b53ff9074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.259753942489624\n",
      "500 155.93272495269775\n",
      "1000 311.0337290763855\n",
      "1500 463.6508901119232\n",
      "2000 616.420068025589\n",
      "2500 769.2170321941376\n",
      "3000 921.1402971744537\n",
      "3500 1072.6364212036133\n",
      "4000 1225.1835062503815\n",
      "4500 1371.7496981620789\n",
      "5000 1505.9199569225311\n",
      "5500 1637.9951720237732\n",
      "6000 1770.7348041534424\n",
      "1794.1881201267242\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "X_gogn = []\n",
    "y_gogn = []\n",
    "bd_all = {}\n",
    "for st in ['h', 'a', 'r']:\n",
    "    vegir = veg_listi[st]\n",
    "    bd = []\n",
    "    for k in range(vegir.shape[0]):\n",
    "        bns = vegir['geometry'][k].bounds\n",
    "        bd.append(bns)\n",
    "    bd_all[st] = bd\n",
    "for n in range(len(hnitlisti)):\n",
    "    if n % 500 == 0:\n",
    "        print(n, time.time() - byrjun)\n",
    "    hnit = hnitlisti[n]\n",
    "\n",
    "    # Open image\n",
    "    try:\n",
    "        gtm = Image.open(mappa + hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png')\n",
    "        dilar = gtm.load()\n",
    "        if tuple(dilar[0, 0]) == (4, 13, 23) and tuple(dilar[1023, 1023]) == (4, 13, 23):\n",
    "            print('Did not load', hnit)\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    except OSError:\n",
    "        print('OSError', hnit)\n",
    "        continue\n",
    "    \n",
    "    # Convert coordinates\n",
    "    y_n = 1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))) - 0.5\n",
    "    y_s = 1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))) + 0.5\n",
    "    if hnit[0] == 'd':\n",
    "        vegir = veg_listi['h']\n",
    "    else:\n",
    "        vegir = veg_listi[hnit[0]]\n",
    "    hnit_br = (1 / (2 * math.pi) * 2 ** 17 * (math.pi - math.log(math.tan(math.pi / 4 + math.radians(hnit[1]) / 2))),\n",
    "               1 / (2 * math.pi) * 2 ** 17 * (math.pi + math.radians(hnit[2])))\n",
    "    \n",
    "    # Roads\n",
    "    try:\n",
    "        ermedvegi = vegir_json[hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png']\n",
    "    except KeyError:\n",
    "        print('KeyError', n)\n",
    "        if hnit[0] == 'd':\n",
    "            bd = bd_all['h']\n",
    "        else:\n",
    "            bd = bd_all[hnit[0]]\n",
    "        ermedvegi = [0, 0, 0, 0]\n",
    "        hNN = pix2coord(0, 0, hnit_br)\n",
    "        hTT = pix2coord(1024, 1024, hnit_br)\n",
    "        for v in range(vegir.shape[0]):\n",
    "            bns = bd[v]\n",
    "            if bns[0] > hnit[2] + 0.0014 or bns[1] > hnit[1] + 0.0008 or bns[2] < hnit[2] - 0.0014 or bns[3] < hnit[1] - 0.0008:\n",
    "                continue\n",
    "            NW = coord2pix(bns[3], bns[0], hnit_br)\n",
    "            SE = coord2pix(bns[1], bns[2], hnit_br)\n",
    "            if NW[0] > 1024 or NW[1] > 1024 or SE[0] < 0 or SE[1] < 0:\n",
    "                continue\n",
    "            for lina in vegir.loc[v, 'geometry'].geoms:\n",
    "                x, y = lina.xy\n",
    "                punktlisti = [(y[0], x[0]), (y[1], x[1])]\n",
    "                slope = (y[1] - y[0]) / (x[1] - x[0])\n",
    "                incpt = y[0] - slope * x[0]\n",
    "                if (hNN[1] < x[0] and hNN[1] > x[1]) or (hNN[1] > x[0] and hNN[1] < x[1]):\n",
    "                    punktlisti.append((slope * hNN[1] + incpt, hNN[1]))\n",
    "                if (hnit[2] < x[0] and hnit[2] > x[1]) or (hnit[2] > x[0] and hnit[2] < x[1]):\n",
    "                    punktlisti.append((slope * hnit[2] + incpt, hnit[2]))\n",
    "                if (hTT[1] < x[0] and hTT[1] > x[1]) or (hTT[1] > x[0] and hTT[1] < x[1]):\n",
    "                    punktlisti.append((slope * hTT[1] + incpt, hTT[1]))\n",
    "                slope = (x[1] - x[0]) / (y[1] - y[0])\n",
    "                incpt = x[0] - slope * y[0]\n",
    "                if (hNN[0] < y[0] and hNN[0] > y[1]) or (hNN[0] > y[0] and hNN[0] < y[1]):\n",
    "                    punktlisti.append((hNN[0], slope * hNN[0] + incpt))\n",
    "                if (hnit[1] < y[0] and hnit[1] > y[1]) or (hnit[1] > y[0] and hnit[1] < y[1]):\n",
    "                    punktlisti.append((hnit[1], slope * hnit[1] + incpt))\n",
    "                if (hTT[0] < y[0] and hTT[0] > y[1]) or (hTT[0] > y[0] and hTT[0] < y[1]):\n",
    "                    punktlisti.append((hTT[0], slope * hTT[0] + incpt))\n",
    "                for p in punktlisti:\n",
    "                    if ermedvegi[0] == 1 and p[0] > hnit[1] and p[1] < hnit[2]:\n",
    "                        continue\n",
    "                    elif ermedvegi[1] == 1 and p[0] > hnit[1] and p[1] > hnit[2]:\n",
    "                        continue\n",
    "                    elif ermedvegi[2] == 1 and p[0] < hnit[1] and p[1] < hnit[2]:\n",
    "                        continue\n",
    "                    elif ermedvegi[3] == 1 and p[0] < hnit[1] and p[1] > hnit[2]:\n",
    "                        continue\n",
    "                    ct = coord2pix(p[0], p[1], hnit_br)\n",
    "                    if ct[0] >= 0 and ct[0] <= 512 and ct[1] >= 0 and ct[1] <= 512:\n",
    "                        ermedvegi[0] = 1\n",
    "                    if ct[0] >= 512 and ct[0] <= 1024 and ct[1] >= 0 and ct[1] <= 512:\n",
    "                        ermedvegi[1] = 1\n",
    "                    if ct[0] >= 0 and ct[0] <= 512 and ct[1] >= 512 and ct[1] <= 1024:\n",
    "                        ermedvegi[2] = 1\n",
    "                    if ct[0] >= 512 and ct[0] <= 1024 and ct[1] >= 512 and ct[1] <= 1024:\n",
    "                        ermedvegi[3] = 1\n",
    "                    if sum(ermedvegi) == 4:\n",
    "                        break\n",
    "                if sum(ermedvegi) == 4:\n",
    "                    break\n",
    "            if sum(ermedvegi) == 4:\n",
    "                break\n",
    "        vegir_json[hnit[0] + '_' + str(hnit[1]) + '_' + str(hnit[2]) + '.png'] = ermedvegi\n",
    "    if hnit[0] != 'd':\n",
    "        frummynd = np.array(gtm.getdata(band=2)).reshape(1024, 1024)\n",
    "        X_gogn.append(torch.tensor(frummynd[:512, :512].reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn.append(torch.tensor(frummynd[:512, 512:].reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn.append(torch.tensor(frummynd[512:, :512].reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        X_gogn.append(torch.tensor(frummynd[512:, 512:].reshape(1, 1, 512, 512), \n",
    "                                   dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[0]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[1]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[2]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "        y_gogn.append(torch.tensor(np.array(ermedvegi[3]).reshape(1, 1), dtype=torch.float16).to(device))\n",
    "    gtm.close()\n",
    "outfile = open(mappa + 'vegir.json', 'w')\n",
    "json.dump(vegir_json, outfile)\n",
    "outfile.close()\n",
    "print(time.time() - byrjun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1c583-8900-4bd8-8a8c-ffe2817b22e4",
   "metadata": {},
   "source": [
    "## Unndís\n",
    "Hérna er CNN.\n",
    "\n",
    "Forritað með aðstoð frá o1-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8202373c-2123-4d7d-bed2-f5eb513eb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGLikan(nn.Module):\n",
    "    def __init__(self, ks, p):\n",
    "        super(VGLikan, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)    # Output: 512x512x16\n",
    "        self.pool = nn.MaxPool2d(2, 2)                                       # Output size halved\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)   # Output: 256x256x32\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)   # Output: 128x128x64\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=ks, stride=1, padding=p, dtype=torch.float16)  # Output: 64x64x128\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 32x32x256\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 16x16x512\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 8x8x512\n",
    "        self.conv8 = nn.Conv2d(512, 512, kernel_size=ks, stride=1, padding=p, dtype=torch.float16) # Output: 4x4x512\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(2 * 2 * 512, 512, dtype=torch.float16)\n",
    "        self.fc2 = nn.Linear(512, 128, dtype=torch.float16)\n",
    "        self.fc3 = nn.Linear(128, 1, dtype=torch.float16)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch_size, 3, 1024, 1024)\n",
    "        x = F.relu(self.conv1(x))  # Output: (batch_size, 16, 512, 512)\n",
    "        x = self.pool(x)           # Output: (batch_size, 16, 256, 256)\n",
    "\n",
    "        x = F.relu(self.conv2(x))  # Output: (batch_size, 32, 256, 256)\n",
    "        x = self.pool(x)           # Output: (batch_size, 32, 128, 128)\n",
    "\n",
    "        x = F.relu(self.conv3(x))  # Output: (batch_size, 64, 128, 128)\n",
    "        x = self.pool(x)           # Output: (batch_size, 64, 64, 64)\n",
    "\n",
    "        x = F.relu(self.conv4(x))  # Output: (batch_size, 128, 64, 64)\n",
    "        x = self.pool(x)           # Output: (batch_size, 128, 32, 32)\n",
    "\n",
    "        x = F.relu(self.conv5(x))  # Output: (batch_size, 256, 32, 32)\n",
    "        x = self.pool(x)           # Output: (batch_size, 256, 16, 16)\n",
    "\n",
    "        x = F.relu(self.conv6(x))  # Output: (batch_size, 512, 16, 16)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 8, 8)\n",
    "\n",
    "        x = F.relu(self.conv7(x))  # Output: (batch_size, 512, 8, 8)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 4, 4)\n",
    "\n",
    "        x = F.relu(self.conv8(x))  # Output: (batch_size, 512, 4, 4)\n",
    "        x = self.pool(x)           # Output: (batch_size, 512, 2, 2)\n",
    "\n",
    "        x = x.view(-1, 2 * 2 * 512)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))      # Fully connected layer\n",
    "        x = F.relu(self.fc2(x))      # Fully connected layer\n",
    "        x = self.fc3(x)              # Output layer\n",
    "        x = torch.sigmoid(x)         # Apply sigmoid activation for binary classification\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f84000-11c7-472b-a90f-9ff339a42297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 0 0 | Time: 667.3051111698151\n",
      "1e-06 0 1 | Time: 1287.9152488708496\n",
      "1e-06 0 2 | Time: 2057.9408960342407\n",
      "1e-06 0 3 | Time: 2772.5425732135773\n",
      "1e-06 0 4 | Time: 3461.421054124832\n",
      "1e-06 0.25 0 | Time: 4283.238842964172\n",
      "1e-06 0.25 1 | Time: 5106.715403079987\n",
      "1e-06 0.25 2 | Time: 5881.623640060425\n",
      "1e-06 0.25 3 | Time: 6600.677381038666\n",
      "1e-06 0.25 4 | Time: 7280.4614799022675\n",
      "1e-06 0.5 0 | Time: 8027.530746936798\n",
      "1e-06 0.5 1 | Time: 8814.407491207123\n",
      "1e-06 0.5 2 | Time: 9582.962297916412\n",
      "1e-06 0.5 3 | Time: 10378.275880098343\n",
      "1e-06 0.5 4 | Time: 11122.586222171783\n",
      "5e-06 0 0 | Time: 11851.590271949768\n",
      "5e-06 0 1 | Time: 12597.030042886734\n",
      "5e-06 0 2 | Time: 13326.991758108139\n",
      "5e-06 0 3 | Time: 14072.137512922287\n",
      "5e-06 0 4 | Time: 14846.57256102562\n",
      "5e-06 0.25 0 | Time: 15650.13839006424\n",
      "5e-06 0.25 1 | Time: 16499.75920009613\n",
      "5e-06 0.25 2 | Time: 17329.281511068344\n",
      "5e-06 0.25 3 | Time: 18090.663971185684\n",
      "5e-06 0.25 4 | Time: 18849.411981105804\n",
      "5e-06 0.5 0 | Time: 19678.959055900574\n",
      "5e-06 0.5 1 | Time: 20620.049141168594\n",
      "5e-06 0.5 2 | Time: 21798.88277721405\n",
      "5e-06 0.5 3 | Time: 22946.224473953247\n",
      "5e-06 0.5 4 | Time: 24178.38464808464\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "outfile = open(mappa + '../envalys-nathan/tilraunir.csv', 'w')\n",
    "ritari = csv.writer(outfile)\n",
    "ritari.writerow(['Learning rate', 'Momentum', 'Random state', 'Train diff (1)', 'Test diff (1)', 'Train diff (2)', 'Test diff (2)'])\n",
    "for a in [1e-6, 5e-6]:  # Learning rate\n",
    "    for b in [0, 0.25, 0.5]:  # Momentum\n",
    "        for c in range(5):  # Random state\n",
    "            # Initialize model\n",
    "            likan = VGLikan(3, 1).to(device)\n",
    "            \n",
    "            # Define a loss function and optimizer\n",
    "            criterion = nn.BCELoss()\n",
    "            optimizer = optim.SGD(likan.parameters(), lr=a, momentum=b)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_gogn, y_gogn, random_state=c)\n",
    "            \n",
    "            train_loss = []\n",
    "            test_loss = []\n",
    "            \n",
    "            for e in range(2):  # Epochs\n",
    "                likan.eval()\n",
    "                with torch.no_grad():\n",
    "                    rl = 0.0\n",
    "                    for i in range(len(X_train)):\n",
    "                        y_pred = likan(X_train[i])\n",
    "                        loss = criterion(y_pred, y_train[i])\n",
    "                        rl += loss.item()\n",
    "                    train_loss.append(rl / len(X_train))\n",
    "                    rl = 0.0\n",
    "                    for i in range(len(X_test)):\n",
    "                        y_pred = likan(X_test[i])\n",
    "                        loss = criterion(y_pred, y_test[i])\n",
    "                        rl += loss.item()\n",
    "                    test_loss.append(rl / len(X_test))\n",
    "                torch.mps.empty_cache()\n",
    "                    \n",
    "                likan.train()\n",
    "                for i in range(len(X_train)):\n",
    "                    y_pred = likan(X_train[i])\n",
    "                    loss = criterion(y_pred, y_train[i])\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "                    torch.mps.synchronize()\n",
    "                    if i % 10 == 0:\n",
    "                        torch.mps.empty_cache()\n",
    "                    \n",
    "                torch.mps.empty_cache()\n",
    "            \n",
    "            likan.eval()\n",
    "            with torch.no_grad():\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_train)):\n",
    "                    y_pred = likan(X_train[i])\n",
    "                    loss = criterion(y_pred, y_train[i])\n",
    "                    rl += loss.item()\n",
    "                train_loss.append(rl / len(X_train))\n",
    "                rl = 0.0\n",
    "                for i in range(len(X_test)):\n",
    "                    y_pred = likan(X_test[i])\n",
    "                    loss = criterion(y_pred, y_test[i])\n",
    "                    rl += loss.item()\n",
    "                test_loss.append(rl / len(X_test))\n",
    "            torch.mps.empty_cache()\n",
    "        \n",
    "            # Print loss for the current epoch\n",
    "            print(a, b, c, '| Time:', time.time() - byrjun)\n",
    "\n",
    "            ritari.writerow([a, b, c, train_loss[0] - train_loss[1], test_loss[0] - test_loss[1],\n",
    "                             train_loss[1] - train_loss[2], test_loss[1] - test_loss[2]])\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532eee4-7f2b-43b8-ae3b-f75f05ba8560",
   "metadata": {},
   "source": [
    "## Lokaorð\n",
    "Þetta líkan er ekki nógu gott. Ég reyndi að þjálfa líkanið með 3.000 myndum, en það var of mikið fyrir tölvuna mína."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54225e83-d1dc-417f-ab31-51a54c3ff6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
