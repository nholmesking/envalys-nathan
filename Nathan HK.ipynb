{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970ab42f-e0b5-47e2-bca7-e268dd9acaec",
   "metadata": {},
   "source": [
    "# Notkun gervigreindar fyrir greiningu á þrívíddarmyndum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c4b5e-f8a0-40e4-9a20-fce177517b49",
   "metadata": {},
   "source": [
    "Nathan Holmes-King"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1d3ccaa-e673-4dcf-9068-325a8d71f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywikibot\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stl import mesh\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cpu\")#\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f14fa6-f58f-4887-b619-09ded63df20d",
   "metadata": {},
   "source": [
    "## Inngangsorð\n",
    "Við ætlum að þjálfa gervigreindarlíkan til að greina þrívíddarmyndir. Í notkun eru líkön sem geta það, en þau nota alltaf \"bitmap\"-myndir. Þetta líkan hér notar \"vector\"-myndir eins og Envalys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5a80b-f925-4de4-a0cb-4ecfbdd55f23",
   "metadata": {},
   "source": [
    "## Gögn\n",
    "Þessi gögn eru STL-skrár frá Wikimedia Commons. Það eru fimm flokkar:\n",
    "- líkamshlutar\n",
    "- byggingar\n",
    "- rúmfræði\n",
    "- geimfarartæki\n",
    "- styttur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a48e65-ff71-4dff-95a0-621dea4d722a",
   "metadata": {},
   "source": [
    "### Sækja gögn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a80470d-2fe8-4a13-8c49-07d5253f0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "flokkar = ['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
    "skrar = {}\n",
    "catnum = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aadeeb0f-d6b6-4bdf-9fba-2979297056b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body parts\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "buildings\n",
      "0\n",
      "10\n",
      "20\n",
      "geometric shapes\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "objects in space\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "sculptures\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "commons = pywikibot.Site('commons', 'commons')\n",
    "cn = 0\n",
    "for a in flokkar:\n",
    "    print(a)\n",
    "    cat = pywikibot.Category(commons, 'STL files of ' + a)\n",
    "    catnum[a] = cn\n",
    "    cn += 1\n",
    "    n = 0\n",
    "    for p in cat.members(member_type=['file']):\n",
    "        if n % 10 == 0:\n",
    "            print(n)\n",
    "        mynd = pywikibot.FilePage(p)\n",
    "        try:\n",
    "            tempf = open('/Users/002-nathan/Desktop/Envalys/STLdata/' + a + '_' + p.title()[5:], 'r')\n",
    "            tempf.close()\n",
    "        except FileNotFoundError:\n",
    "            mynd.download(filename='/Users/002-nathan/Desktop/Envalys/STLdata/' + a + '_' + p.title()[5:])\n",
    "        try:\n",
    "            skrar[a].append(p.title()[5:])\n",
    "        except KeyError:\n",
    "            skrar[a] = [p.title()[5:]]\n",
    "        n += 1\n",
    "        if n >= 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af781434-8e30-4444-a693-c601f559cbbe",
   "metadata": {},
   "source": [
    "### Setja upp gögn fyrir notkun\n",
    "Við deilum myndinni í 2.097.152 (128x128x128) þrívíddardíla eða \"voxels\", teljum punktana í hverjum díl, og notum töluna til að greina myndina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ed15642-7cd9-4d0e-ac83-2f84bd7273eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body parts\n",
      "45.23072910308838\n",
      "----\n",
      "buildings\n",
      "25.889988899230957\n",
      "----\n",
      "geometric shapes\n",
      "32.926254987716675\n",
      "----\n",
      "objects in space\n",
      "exception (False, 'No lines found, impossible to read')\n",
      "46.50938415527344\n",
      "----\n",
      "sculptures\n",
      "118.43725895881653\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "X_preproc = []\n",
    "y_preproc = []\n",
    "for cat in skrar:\n",
    "    print(cat)\n",
    "    byrjun = time.time()\n",
    "    for fi in skrar[cat]:\n",
    "        # Load data\n",
    "        gogn = mesh.Mesh.from_file('/Users/002-nathan/Desktop/Envalys/STLdata/' + cat + '_' + fi)\n",
    "        # Re-scale to be \n",
    "        gogn_x = [a[0] for a in gogn.v0]# + [a[0] for a in gogn.v1] + [a[0] for a in gogn.v2]\n",
    "        gogn_y = [a[1] for a in gogn.v0]# + [a[1] for a in gogn.v1] + [a[1] for a in gogn.v2]\n",
    "        gogn_z = [a[2] for a in gogn.v0]# + [a[2] for a in gogn.v1] + [a[2] for a in gogn.v2]\n",
    "        minx = min(gogn_x)\n",
    "        miny = min(gogn_y)\n",
    "        minz = min(gogn_z)\n",
    "        scale = min(128 / (max(gogn_x) + 1e-3 - minx), \n",
    "                    128 / (max(gogn_y) + 1e-3 - miny), \n",
    "                    128 / (max(gogn_z) + 1e-3 - minz))\n",
    "        ny_gogn = np.zeros((1, 128, 128, 128), dtype=np.float32)\n",
    "        for a in gogn.v0:\n",
    "            x = int((a[0] - minx) * scale)\n",
    "            y = int((a[1] - miny) * scale)\n",
    "            z = int((a[2] - minz) * scale)\n",
    "            ny_gogn[0][x][y][z] += 1\n",
    "        X_preproc.append(ny_gogn)\n",
    "        y_preproc.append([catnum[cat]])\n",
    "    print(time.time() - byrjun)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abd1fbba-0c01-46b6-9ada-9264b7368d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "for a in X_preproc:\n",
    "    X_data.append(torch.from_numpy(a).to(device))\n",
    "for a in y_preproc:\n",
    "    y_data.append(torch.tensor(a).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2e0e5-6430-4a8a-8abe-2447a02233e9",
   "metadata": {},
   "source": [
    "## Líkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50523aef-6ef1-4268-a44d-a5b724773d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class likan(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(likan, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, 5, padding=2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 5, padding=2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 5, padding=2)\n",
    "        self.fc1 = nn.Linear(64*16*16*16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 5)  # Change second param\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = x.view(-1, 64*16*16*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccd82e93-6f32-41a2-88de-0bcb68ae2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "848d23a9-0cf4-4139-ba2b-3845948f5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "Train accuracy: 0.33507853403141363\n",
      "[[64  0  0  0  0]\n",
      " [19  0  0  0  0]\n",
      " [33  0  0  0  0]\n",
      " [32  0  0  0  0]\n",
      " [43  0  0  0  0]]\n",
      "Test accuracy: 0.28125\n",
      "[[18  0  0  0  0]\n",
      " [ 5  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [19  0  0  0  0]\n",
      " [10  0  0  0  0]]\n",
      "Time: 700.9412417411804\n",
      "----\n",
      "Random state: 1\n",
      "Train accuracy: 0.31413612565445026\n",
      "[[60  0  0  0  0]\n",
      " [19  0  0  0  0]\n",
      " [34  0  0  0  0]\n",
      " [37  0  0  0  0]\n",
      " [41  0  0  0  0]]\n",
      "Test accuracy: 0.34375\n",
      "[[22  0  0  0  0]\n",
      " [ 5  0  0  0  0]\n",
      " [11  0  0  0  0]\n",
      " [14  0  0  0  0]\n",
      " [12  0  0  0  0]]\n",
      "Time: 1394.9648568630219\n",
      "----\n",
      "Random state: 2\n",
      "Train accuracy: 0.3089005235602094\n",
      "[[59  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [34  0  0  0  0]\n",
      " [41  0  0  0  0]\n",
      " [40  0  0  0  0]]\n",
      "Test accuracy: 0.359375\n",
      "[[23  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [11  0  0  0  0]\n",
      " [10  0  0  0  0]\n",
      " [13  0  0  0  0]]\n",
      "Time: 2128.283779859543\n",
      "----\n",
      "Random state: 3\n",
      "Train accuracy: 0.29842931937172773\n",
      "[[57  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [37  0  0  0  0]\n",
      " [38  0  0  0  0]\n",
      " [42  0  0  0  0]]\n",
      "Test accuracy: 0.390625\n",
      "[[25  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 8  0  0  0  0]\n",
      " [13  0  0  0  0]\n",
      " [11  0  0  0  0]]\n",
      "Time: 2852.0083417892456\n",
      "----\n",
      "Random state: 4\n",
      "Train accuracy: 0.32460732984293195\n",
      "[[62  0  0  0  0]\n",
      " [15  0  0  0  0]\n",
      " [33  0  0  0  0]\n",
      " [43  0  0  0  0]\n",
      " [38  0  0  0  0]]\n",
      "Test accuracy: 0.3125\n",
      "[[20  0  0  0  0]\n",
      " [ 9  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [ 8  0  0  0  0]\n",
      " [15  0  0  0  0]]\n",
      "Time: 3592.125574827194\n",
      "----\n",
      "Random state: 5\n",
      "Train accuracy: 0.3193717277486911\n",
      "[[61  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [35  0  0  0  0]\n",
      " [38  0  0  0  0]\n",
      " [40  0  0  0  0]]\n",
      "Test accuracy: 0.328125\n",
      "[[21  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [10  0  0  0  0]\n",
      " [13  0  0  0  0]\n",
      " [13  0  0  0  0]]\n",
      "Time: 4316.436213970184\n",
      "----\n",
      "Random state: 6\n",
      "Train accuracy: 0.3298429319371728\n",
      "[[59  0  0  0  4]\n",
      " [14  0  0  0  1]\n",
      " [35  0  0  0  0]\n",
      " [32  0  0  0  2]\n",
      " [40  0  0  0  4]]\n",
      "Test accuracy: 0.28125\n",
      "[[18  0  0  0  1]\n",
      " [ 9  0  0  0  0]\n",
      " [10  0  0  0  0]\n",
      " [14  0  0  0  3]\n",
      " [ 9  0  0  0  0]]\n",
      "Time: 5077.595556735992\n",
      "----\n",
      "Random state: 7\n",
      "Train accuracy: 0.31413612565445026\n",
      "[[60  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [34  0  0  0  0]\n",
      " [41  0  0  0  0]\n",
      " [39  0  0  0  0]]\n",
      "Test accuracy: 0.34375\n",
      "[[22  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [11  0  0  0  0]\n",
      " [10  0  0  0  0]\n",
      " [14  0  0  0  0]]\n",
      "Time: 5812.424120903015\n",
      "----\n",
      "Random state: 8\n",
      "Train accuracy: 0.3193717277486911\n",
      "[[61  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [36  0  0  0  0]\n",
      " [38  0  0  0  0]\n",
      " [39  0  0  0  0]]\n",
      "Test accuracy: 0.328125\n",
      "[[21  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 9  0  0  0  0]\n",
      " [13  0  0  0  0]\n",
      " [14  0  0  0  0]]\n",
      "Time: 6557.60945391655\n",
      "----\n",
      "Random state: 9\n",
      "Train accuracy: 0.2879581151832461\n",
      "[[55  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [35  0  0  0  0]\n",
      " [40  0  0  0  0]\n",
      " [43  0  0  0  0]]\n",
      "Test accuracy: 0.421875\n",
      "[[27  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [10  0  0  0  0]\n",
      " [11  0  0  0  0]\n",
      " [10  0  0  0  0]]\n",
      "Time: 7255.53577375412\n",
      "----\n",
      "Mean test accuracy: 0.3390625\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "acc = []\n",
    "for i in range(10):\n",
    "    print('Random state:', i)\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for a in X_preproc:\n",
    "        X_data.append(torch.from_numpy(a).to(device))\n",
    "    for a in y_preproc:\n",
    "        y_data.append(torch.tensor(a).to(device))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=i)\n",
    "    model = likan()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for n in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train[n])\n",
    "        loss = F.nll_loss(output, y_train[n])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    trainmat = np.zeros((5, 5), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_train)):\n",
    "            output = model(X_train[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_train[n]).sum().item()\n",
    "            trainmat[y_train[n].item()][y_pred.item()] += 1\n",
    "    print('Train accuracy:', correct / len(y_train))\n",
    "    print(trainmat)\n",
    "    testmat = np.zeros((5, 5), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_test)):\n",
    "            output = model(X_test[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_test[n]).sum().item()\n",
    "            testmat[y_test[n].item()][y_pred.item()] += 1\n",
    "    print('Test accuracy:', correct / len(y_test))\n",
    "    print(testmat)\n",
    "    acc.append(correct / len(y_test))\n",
    "    print('Time:', time.time() - byrjun)\n",
    "    print('----')\n",
    "print('Mean test accuracy:', np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f7879-f9f3-4e9a-ab8b-6fb12ca361f6",
   "metadata": {},
   "source": [
    "Níu líkön úr tíu spá að allar myndir séu líkamshlutar. Er þetta af því það eru ekki nógar myndir í hinum flokkunum? Líkan 6 er með 44 styttumyndir í \"train\"-gögnunum, sem er það flesta í öllum lotunum, og er það einasta sem spáir aðra flokka. Nú skulum við þjálfa líkön án líkamshlutamynda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c1c9572-6cf5-4bc8-8ffd-d1f36843dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class likan_alh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(likan_alh, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, 5, padding=2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 5, padding=2)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 5, padding=2)\n",
    "        self.fc1 = nn.Linear(64*16*16*16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 4)  # Change second param\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool3d(x, 2)\n",
    "        x = x.view(-1, 64*16*16*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99d4a69c-b110-48cd-96aa-63973e645507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "Train accuracy: 0.14728682170542637\n",
      "[[19  0  0  0]\n",
      " [30  0  0  0]\n",
      " [38  0  0  0]\n",
      " [42  0  0  0]]\n",
      "Test accuracy: 0.11363636363636363\n",
      "[[ 5  0  0  0]\n",
      " [15  0  0  0]\n",
      " [13  0  0  0]\n",
      " [11  0  0  0]]\n",
      "Time: 580.6093430519104\n",
      "----\n",
      "Random state: 1\n",
      "Train accuracy: 0.13953488372093023\n",
      "[[18  0  0  0]\n",
      " [33  0  0  0]\n",
      " [35  0  0  0]\n",
      " [43  0  0  0]]\n",
      "Test accuracy: 0.13636363636363635\n",
      "[[ 6  0  0  0]\n",
      " [12  0  0  0]\n",
      " [16  0  0  0]\n",
      " [10  0  0  0]]\n",
      "Time: 1114.7346620559692\n",
      "----\n",
      "Random state: 2\n",
      "Train accuracy: 0.12403100775193798\n",
      "[[16  0  0  0]\n",
      " [33  0  0  0]\n",
      " [38  0  0  0]\n",
      " [42  0  0  0]]\n",
      "Test accuracy: 0.18181818181818182\n",
      "[[ 8  0  0  0]\n",
      " [12  0  0  0]\n",
      " [13  0  0  0]\n",
      " [11  0  0  0]]\n",
      "Time: 1588.4203751087189\n",
      "----\n",
      "Random state: 3\n",
      "Train accuracy: 0.13953488372093023\n",
      "[[18  0  0  0]\n",
      " [32  0  0  0]\n",
      " [38  0  0  0]\n",
      " [41  0  0  0]]\n",
      "Test accuracy: 0.13636363636363635\n",
      "[[ 6  0  0  0]\n",
      " [13  0  0  0]\n",
      " [13  0  0  0]\n",
      " [12  0  0  0]]\n",
      "Time: 2077.139023065567\n",
      "----\n",
      "Random state: 4\n",
      "Train accuracy: 0.11627906976744186\n",
      "[[15  0  0  0]\n",
      " [38  0  0  0]\n",
      " [37  0  0  0]\n",
      " [39  0  0  0]]\n",
      "Test accuracy: 0.20454545454545456\n",
      "[[ 9  0  0  0]\n",
      " [ 7  0  0  0]\n",
      " [14  0  0  0]\n",
      " [14  0  0  0]]\n",
      "Time: 2587.389703273773\n",
      "----\n",
      "Random state: 5\n",
      "Train accuracy: 0.15503875968992248\n",
      "[[20  0  0  0]\n",
      " [29  0  0  0]\n",
      " [40  0  0  0]\n",
      " [40  0  0  0]]\n",
      "Test accuracy: 0.09090909090909091\n",
      "[[ 4  0  0  0]\n",
      " [16  0  0  0]\n",
      " [11  0  0  0]\n",
      " [13  0  0  0]]\n",
      "Time: 3101.1827261447906\n",
      "----\n",
      "Random state: 6\n",
      "Train accuracy: 0.31007751937984496\n",
      "[[ 0  0  0 17]\n",
      " [ 0  0  0 34]\n",
      " [ 0  1  0 37]\n",
      " [ 0  0  0 40]]\n",
      "Test accuracy: 0.29545454545454547\n",
      "[[ 0  0  0  7]\n",
      " [ 0  0  0 11]\n",
      " [ 0  0  0 13]\n",
      " [ 0  0  0 13]]\n",
      "Time: 3631.818634033203\n",
      "----\n",
      "Random state: 7\n",
      "Train accuracy: 0.17054263565891473\n",
      "[[22  0  0  0]\n",
      " [36  0  0  0]\n",
      " [38  0  0  0]\n",
      " [33  0  0  0]]\n",
      "Test accuracy: 0.045454545454545456\n",
      "[[ 2  0  0  0]\n",
      " [ 9  0  0  0]\n",
      " [13  0  0  0]\n",
      " [20  0  0  0]]\n",
      "Time: 4106.121928215027\n",
      "----\n",
      "Random state: 8\n",
      "Train accuracy: 0.14728682170542637\n",
      "[[19  0  0  0]\n",
      " [33  0  0  0]\n",
      " [38  0  0  0]\n",
      " [39  0  0  0]]\n",
      "Test accuracy: 0.11363636363636363\n",
      "[[ 5  0  0  0]\n",
      " [12  0  0  0]\n",
      " [13  0  0  0]\n",
      " [14  0  0  0]]\n",
      "Time: 4587.981192111969\n",
      "----\n",
      "Random state: 9\n",
      "Train accuracy: 0.13178294573643412\n",
      "[[17  0  0  0]\n",
      " [28  0  0  0]\n",
      " [42  0  0  0]\n",
      " [42  0  0  0]]\n",
      "Test accuracy: 0.1590909090909091\n",
      "[[ 7  0  0  0]\n",
      " [17  0  0  0]\n",
      " [ 9  0  0  0]\n",
      " [11  0  0  0]]\n",
      "Time: 5066.659296035767\n",
      "----\n",
      "Mean test accuracy: 0.14772727272727273\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "acc = []\n",
    "for i in range(10):\n",
    "    print('Random state:', i)\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    j = 0\n",
    "    while j < len(X_preproc):\n",
    "        if y_preproc[j][0] != 0:\n",
    "            X_data.append(torch.from_numpy(X_preproc[j]).to(device))\n",
    "            y_data.append(torch.tensor(y_preproc[j]).to(device) - 1)\n",
    "        j += 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=i)\n",
    "    model = likan_alh()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for n in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train[n])\n",
    "        loss = F.nll_loss(output, y_train[n])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    trainmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_train)):\n",
    "            output = model(X_train[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_train[n]).sum().item()\n",
    "            trainmat[y_train[n].item()][y_pred.item()] += 1\n",
    "    print('Train accuracy:', correct / len(y_train))\n",
    "    print(trainmat)\n",
    "    testmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_test)):\n",
    "            output = model(X_test[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_test[n]).sum().item()\n",
    "            testmat[y_test[n].item()][y_pred.item()] += 1\n",
    "    print('Test accuracy:', correct / len(y_test))\n",
    "    print(testmat)\n",
    "    acc.append(correct / len(y_test))\n",
    "    print('Time:', time.time() - byrjun)\n",
    "    print('----')\n",
    "print('Mean test accuracy:', np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837874e-d8e4-4a07-8d9b-fd75556ece80",
   "metadata": {},
   "source": [
    "Nú spáir níu líkön úr tíu að allar myndir séu byggingar, þrátt fyrir því að byggingamyndir eru fæstar í öllum líkönum. Líkan 6 spáir að allar myndir nema ein séu styttur. Við skulum prófa aftur með líkönum 0 og 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5b09695-bb15-4af7-a1eb-a1aa913278ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "Train accuracy: 0.14728682170542637\n",
      "[[19  0  0  0]\n",
      " [30  0  0  0]\n",
      " [38  0  0  0]\n",
      " [42  0  0  0]]\n",
      "Test accuracy: 0.11363636363636363\n",
      "[[ 5  0  0  0]\n",
      " [15  0  0  0]\n",
      " [13  0  0  0]\n",
      " [11  0  0  0]]\n",
      "Time: 482.546923160553\n",
      "----\n",
      "Random state: 6\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([0])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([1])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([2])\n",
      "tensor([[nan, nan, nan, nan]]) tensor([[0]]) tensor([3])\n",
      "Train accuracy: 0.13178294573643412\n",
      "[[17  0  0  0]\n",
      " [34  0  0  0]\n",
      " [38  0  0  0]\n",
      " [40  0  0  0]]\n",
      "Test accuracy: 0.1590909090909091\n",
      "[[ 7  0  0  0]\n",
      " [11  0  0  0]\n",
      " [13  0  0  0]\n",
      " [13  0  0  0]]\n",
      "Time: 987.4681522846222\n",
      "----\n",
      "Mean test accuracy: 0.13636363636363635\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "acc = []\n",
    "for i in [0, 6]:\n",
    "    print('Random state:', i)\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    j = 0\n",
    "    while j < len(X_preproc):\n",
    "        if y_preproc[j][0] != 0:\n",
    "            X_data.append(torch.from_numpy(X_preproc[j]).to(device))\n",
    "            y_data.append(torch.tensor(y_preproc[j]).to(device) - 1)\n",
    "        j += 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=i)\n",
    "    model = likan_alh()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for n in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train[n])\n",
    "        loss = F.nll_loss(output, y_train[n])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    trainmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_train)):\n",
    "            output = model(X_train[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            print(output, y_pred, y_train[n])\n",
    "            correct += y_pred.eq(y_train[n]).sum().item()\n",
    "            trainmat[y_train[n].item()][y_pred.item()] += 1\n",
    "    print('Train accuracy:', correct / len(y_train))\n",
    "    print(trainmat)\n",
    "    testmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_test)):\n",
    "            output = model(X_test[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_test[n]).sum().item()\n",
    "            testmat[y_test[n].item()][y_pred.item()] += 1\n",
    "    print('Test accuracy:', correct / len(y_test))\n",
    "    print(testmat)\n",
    "    acc.append(correct / len(y_test))\n",
    "    print('Time:', time.time() - byrjun)\n",
    "    print('----')\n",
    "print('Mean test accuracy:', np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929f760-32e9-42b2-a222-288d511aa495",
   "metadata": {},
   "source": [
    "Hvaðan koma allar þessar NaN-tölur? Og hvers vegna spáir líkan 6 eitthvað annað en í fyrra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c713ca07-bcf0-4a82-b661-f793d61c50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "0 tensor([[-1.2593, -1.3875, -1.3491, -1.5752]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5752, grad_fn=<NllLossBackward0>)\n",
      "1 tensor([[-1.7825, -1.3764, -1.7435, -0.9054]], grad_fn=<LogSoftmaxBackward0>) tensor(1.7825, grad_fn=<NllLossBackward0>)\n",
      "2 tensor([[-1.1119, -2.4464, -2.7396, -0.6542]], grad_fn=<LogSoftmaxBackward0>) tensor(0.6542, grad_fn=<NllLossBackward0>)\n",
      "3 tensor([[ -2.1972,  -6.3562, -10.3150,  -0.1198]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(10.3150, grad_fn=<NllLossBackward0>)\n",
      "4 tensor([[-3.7430, -2.7885, -0.0946, -5.2860]], grad_fn=<LogSoftmaxBackward0>) tensor(5.2860, grad_fn=<NllLossBackward0>)\n",
      "5 tensor([[-1.4930, -1.3742, -1.3338, -1.3517]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4930, grad_fn=<NllLossBackward0>)\n",
      "6 tensor([[-1.4887, -1.5248, -0.8859, -1.9358]], grad_fn=<LogSoftmaxBackward0>) tensor(1.9358, grad_fn=<NllLossBackward0>)\n",
      "7 tensor([[-4.2736, -3.2277, -3.0028, -0.1089]], grad_fn=<LogSoftmaxBackward0>) tensor(0.1089, grad_fn=<NllLossBackward0>)\n",
      "8 tensor([[-1.7894, -1.6493, -1.4180, -0.9199]], grad_fn=<LogSoftmaxBackward0>) tensor(1.6493, grad_fn=<NllLossBackward0>)\n",
      "9 tensor([[-159.4362, -130.8723, -111.4072,    0.0000]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0., grad_fn=<NllLossBackward0>)\n",
      "10 tensor([[-1.5883, -1.4257, -1.2596, -1.3033]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5883, grad_fn=<NllLossBackward0>)\n",
      "11 tensor([[-2.3438e+01, -9.1642e-04, -2.9061e+01, -6.9954e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(29.0608, grad_fn=<NllLossBackward0>)\n",
      "12 tensor([[-34.5280, -43.8189,   0.0000, -45.0890]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(45.0890, grad_fn=<NllLossBackward0>)\n",
      "13 tensor([[-1.5451e+01, -2.5322e+01, -2.3842e-07, -1.6708e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(16.7082, grad_fn=<NllLossBackward0>)\n",
      "14 tensor([[-1281.1168, -2433.4731,     0.0000,  -775.9172]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0., grad_fn=<NllLossBackward0>)\n",
      "15 tensor([[-45854.4414, -57246.5234, -36266.0391,      0.0000]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0., grad_fn=<NllLossBackward0>)\n",
      "16 tensor([[-11348.9492, -12296.6406, -13655.1855,      0.0000]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(13655.1855, grad_fn=<NllLossBackward0>)\n",
      "17 tensor([[-3.8177e+08, -3.8063e+08,  0.0000e+00, -7.6234e+08]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(3.8063e+08, grad_fn=<NllLossBackward0>)\n",
      "18 tensor([[-1.9930e+17,  0.0000e+00, -3.8812e+17, -2.0717e+17]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(2.0717e+17, grad_fn=<NllLossBackward0>)\n",
      "19 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "20 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "21 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "22 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "23 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "24 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "25 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "26 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "27 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "28 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "29 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "30 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "31 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "32 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "33 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "34 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "35 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "36 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "37 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "38 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "39 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "40 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "41 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "42 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "43 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "44 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "45 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "46 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "47 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "48 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "49 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "50 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "51 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "52 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "53 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "54 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "55 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "56 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "57 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "58 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "59 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "60 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "61 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "62 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "63 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "64 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "65 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "66 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "67 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "68 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "69 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "70 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "71 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "72 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "73 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "74 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "75 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "76 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "77 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "78 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "79 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "80 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "81 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "82 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "83 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "84 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "85 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "86 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "87 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "88 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "89 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "90 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "91 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "92 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "93 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "94 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "95 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "96 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "97 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "98 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "99 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "100 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "101 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "102 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "103 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "104 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "105 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "106 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "107 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "108 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "109 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "110 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "111 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "112 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "113 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "114 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "115 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "116 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "117 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "118 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "119 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "120 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "121 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "122 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "123 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "124 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "125 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "126 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "127 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "128 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "Train accuracy: 0.14728682170542637\n",
      "[[19  0  0  0]\n",
      " [30  0  0  0]\n",
      " [38  0  0  0]\n",
      " [42  0  0  0]]\n",
      "Test accuracy: 0.11363636363636363\n",
      "[[ 5  0  0  0]\n",
      " [15  0  0  0]\n",
      " [13  0  0  0]\n",
      " [11  0  0  0]]\n",
      "Time: 477.5391082763672\n",
      "----\n",
      "Random state: 6\n",
      "0 tensor([[-1.3551, -1.4385, -1.3115, -1.4465]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4385, grad_fn=<NllLossBackward0>)\n",
      "1 tensor([[-1.3873, -1.0652, -1.4229, -1.8044]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4229, grad_fn=<NllLossBackward0>)\n",
      "2 tensor([[-1.3698, -1.4644, -1.2339, -1.4984]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3698, grad_fn=<NllLossBackward0>)\n",
      "3 tensor([[-1.2906, -2.4080, -0.4576, -6.1746]], grad_fn=<LogSoftmaxBackward0>) tensor(0.4576, grad_fn=<NllLossBackward0>)\n",
      "4 tensor([[-2.1626e+01, -1.9075e+01, -1.1921e-07, -1.6529e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(1.1921e-07, grad_fn=<NllLossBackward0>)\n",
      "5 tensor([[-7.4264, -6.0040, -0.0086, -5.2081]], grad_fn=<LogSoftmaxBackward0>) tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "6 tensor([[-1.9961, -1.6231, -0.7460, -1.6471]], grad_fn=<LogSoftmaxBackward0>) tensor(1.6231, grad_fn=<NllLossBackward0>)\n",
      "7 tensor([[-1.3131e+01, -9.7627e+00, -1.2755e-04, -9.5965e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(13.1314, grad_fn=<NllLossBackward0>)\n",
      "8 tensor([[-0.5067, -1.3750, -2.1678, -3.4984]], grad_fn=<LogSoftmaxBackward0>) tensor(3.4984, grad_fn=<NllLossBackward0>)\n",
      "9 tensor([[-1.1212, -1.4230, -1.6812, -1.3984]], grad_fn=<LogSoftmaxBackward0>) tensor(1.6812, grad_fn=<NllLossBackward0>)\n",
      "10 tensor([[-1.3735, -1.4293, -1.3332, -1.4120]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4293, grad_fn=<NllLossBackward0>)\n",
      "11 tensor([[-1.3993, -1.4328, -1.3339, -1.3818]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3993, grad_fn=<NllLossBackward0>)\n",
      "12 tensor([[-1.2092, -1.4439, -1.6335, -1.3081]], grad_fn=<LogSoftmaxBackward0>) tensor(1.6335, grad_fn=<NllLossBackward0>)\n",
      "13 tensor([[-1.3517, -1.4016, -1.3385, -1.4577]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3517, grad_fn=<NllLossBackward0>)\n",
      "14 tensor([[-1.5930, -1.6761, -1.4976, -0.9522]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4976, grad_fn=<NllLossBackward0>)\n",
      "15 tensor([[-1.3226, -1.4244, -1.3529, -1.4507]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4244, grad_fn=<NllLossBackward0>)\n",
      "16 tensor([[-1.3633, -1.4220, -1.2985, -1.4697]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3633, grad_fn=<NllLossBackward0>)\n",
      "17 tensor([[-8.4504e+00, -7.4991e+00, -4.8890e+00, -8.3311e-03]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(4.8890, grad_fn=<NllLossBackward0>)\n",
      "18 tensor([[-3.9554, -5.0638, -0.8364, -0.6138]], grad_fn=<LogSoftmaxBackward0>) tensor(0.6138, grad_fn=<NllLossBackward0>)\n",
      "19 tensor([[-0.8693, -3.5902, -4.4135, -0.6142]], grad_fn=<LogSoftmaxBackward0>) tensor(4.4135, grad_fn=<NllLossBackward0>)\n",
      "20 tensor([[-5.9605e-07, -1.4842e+01, -2.8924e+01, -1.5053e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(28.9238, grad_fn=<NllLossBackward0>)\n",
      "21 tensor([[-0.0498, -4.8283, -7.5350, -3.2170]], grad_fn=<LogSoftmaxBackward0>) tensor(7.5350, grad_fn=<NllLossBackward0>)\n",
      "22 tensor([[-1.4125, -1.4164, -1.1757, -1.5835]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4125, grad_fn=<NllLossBackward0>)\n",
      "23 tensor([[-6.2345, -4.2610, -0.0193, -5.8041]], grad_fn=<LogSoftmaxBackward0>) tensor(5.8041, grad_fn=<NllLossBackward0>)\n",
      "24 tensor([[-1.4811, -1.4293, -1.1499, -1.5303]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4293, grad_fn=<NllLossBackward0>)\n",
      "25 tensor([[-1.4996, -1.4130, -1.1210, -1.5730]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1210, grad_fn=<NllLossBackward0>)\n",
      "26 tensor([[-1.3865, -1.4077, -1.2531, -1.5153]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4077, grad_fn=<NllLossBackward0>)\n",
      "27 tensor([[-1.4490, -1.3907, -1.2077, -1.5260]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3907, grad_fn=<NllLossBackward0>)\n",
      "28 tensor([[-1.6256, -1.4155, -1.0472, -1.5631]], grad_fn=<LogSoftmaxBackward0>) tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "29 tensor([[-1.5377, -1.3978, -1.1425, -1.5188]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3978, grad_fn=<NllLossBackward0>)\n",
      "30 tensor([[-1.5589e+01, -9.6370e+00, -7.9986e-05, -1.1140e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(11.1400, grad_fn=<NllLossBackward0>)\n",
      "31 tensor([[-1.7949, -1.8308, -1.7714, -0.6862]], grad_fn=<LogSoftmaxBackward0>) tensor(0.6862, grad_fn=<NllLossBackward0>)\n",
      "32 tensor([[-2652.6729, -1132.7983,     0.0000,  -423.4785]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(423.4785, grad_fn=<NllLossBackward0>)\n",
      "33 tensor([[-5.5877e+09, -5.5054e+09, -1.0874e+10,  0.0000e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0., grad_fn=<NllLossBackward0>)\n",
      "34 tensor([[-25950996., -25507978., -49906168.,         0.]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(25950996., grad_fn=<NllLossBackward0>)\n",
      "35 tensor([[ 0.0000e+00, -2.7553e+09, -5.9370e+09, -2.3160e+09]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(2.7553e+09, grad_fn=<NllLossBackward0>)\n",
      "36 tensor([[-1.4876e+35,  0.0000e+00, -7.4379e+34, -7.4379e+34]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(7.4379e+34, grad_fn=<NllLossBackward0>)\n",
      "37 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "38 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "39 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "40 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "41 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "42 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "43 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "44 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "45 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "46 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "47 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "48 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "49 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "50 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "51 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "52 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "53 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "54 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "55 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "56 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "57 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "58 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "59 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "60 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "61 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "62 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "63 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "64 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "65 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "66 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "67 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "68 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "69 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "70 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "71 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "72 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "73 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "74 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "75 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "76 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "77 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "78 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "79 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "80 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "81 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "82 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "83 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "84 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "85 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "86 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "87 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "88 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "89 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "90 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "91 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "92 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "93 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "94 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "95 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "96 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "97 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "98 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "99 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "100 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "101 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "102 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "103 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "104 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "105 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "106 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "107 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "108 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "109 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "110 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "111 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "112 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "113 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "114 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "115 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "116 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "117 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "118 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "119 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "120 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "121 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "122 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "123 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "124 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "125 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "126 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "127 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "128 tensor([[nan, nan, nan, nan]], grad_fn=<LogSoftmaxBackward0>) tensor(nan, grad_fn=<NllLossBackward0>)\n",
      "Train accuracy: 0.13178294573643412\n",
      "[[17  0  0  0]\n",
      " [34  0  0  0]\n",
      " [38  0  0  0]\n",
      " [40  0  0  0]]\n",
      "Test accuracy: 0.1590909090909091\n",
      "[[ 7  0  0  0]\n",
      " [11  0  0  0]\n",
      " [13  0  0  0]\n",
      " [13  0  0  0]]\n",
      "Time: 927.9041001796722\n",
      "----\n",
      "Mean test accuracy: 0.13636363636363635\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "acc = []\n",
    "for i in [0, 6]:\n",
    "    print('Random state:', i)\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    j = 0\n",
    "    while j < len(X_preproc):\n",
    "        if y_preproc[j][0] != 0:\n",
    "            X_data.append(torch.from_numpy(X_preproc[j]).to(device))\n",
    "            y_data.append(torch.tensor(y_preproc[j]).to(device) - 1)\n",
    "        j += 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=i)\n",
    "    model = likan_alh()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for n in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train[n])\n",
    "        loss = F.nll_loss(output, y_train[n])\n",
    "        print(n, output, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    trainmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_train)):\n",
    "            output = model(X_train[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_train[n]).sum().item()\n",
    "            trainmat[y_train[n].item()][y_pred.item()] += 1\n",
    "    print('Train accuracy:', correct / len(y_train))\n",
    "    print(trainmat)\n",
    "    testmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_test)):\n",
    "            output = model(X_test[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_test[n]).sum().item()\n",
    "            testmat[y_test[n].item()][y_pred.item()] += 1\n",
    "    print('Test accuracy:', correct / len(y_test))\n",
    "    print(testmat)\n",
    "    acc.append(correct / len(y_test))\n",
    "    print('Time:', time.time() - byrjun)\n",
    "    print('----')\n",
    "print('Mean test accuracy:', np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ef819-dc82-410b-93cd-0c938feebfb0",
   "metadata": {},
   "source": [
    "Kannski eigum við að lækka námshraðann (\"learning rate\"). Og líkan 6 var bara heppið; það tók nærri tveim sinnum lengra til að verða NaN en líkan 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07bdbd7b-0a33-4daa-b2d4-8a303ef1449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "985b4b77-4748-4098-b385-414072f29ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "0 tensor([[-1.5538, -1.2743, -1.4360, -1.3055]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3055, grad_fn=<NllLossBackward0>)\n",
      "1 tensor([[-1.4058, -1.4876, -1.3623, -1.2989]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4058, grad_fn=<NllLossBackward0>)\n",
      "2 tensor([[-1.5877, -1.2475, -1.5297, -1.2318]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2318, grad_fn=<NllLossBackward0>)\n",
      "3 tensor([[-1.2168, -1.6360, -1.4493, -1.2934]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4493, grad_fn=<NllLossBackward0>)\n",
      "4 tensor([[-4.4423, -1.3190, -4.5708, -0.3418]], grad_fn=<LogSoftmaxBackward0>) tensor(0.3418, grad_fn=<NllLossBackward0>)\n",
      "5 tensor([[-1.3925, -1.4994, -1.3392, -1.3234]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3925, grad_fn=<NllLossBackward0>)\n",
      "6 tensor([[-2.1605, -1.8004, -1.2008, -0.8710]], grad_fn=<LogSoftmaxBackward0>) tensor(0.8710, grad_fn=<NllLossBackward0>)\n",
      "7 tensor([[-27.6683, -29.9345, -22.5681,   0.0000]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0., grad_fn=<NllLossBackward0>)\n",
      "8 tensor([[-1.3540, -1.5369, -1.3585, -1.3105]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5369, grad_fn=<NllLossBackward0>)\n",
      "9 tensor([[-1.4157e+01, -1.2262e+01, -1.7701e+01, -5.4836e-06]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(5.4836e-06, grad_fn=<NllLossBackward0>)\n",
      "10 tensor([[-1.3522, -1.5226, -1.3533, -1.3288]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3522, grad_fn=<NllLossBackward0>)\n",
      "11 tensor([[-9.4104e+00, -1.3276e+01, -1.1947e+01, -9.0118e-05]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(11.9466, grad_fn=<NllLossBackward0>)\n",
      "12 tensor([[-3.3216, -6.0136, -3.1491, -0.0849]], grad_fn=<LogSoftmaxBackward0>) tensor(0.0849, grad_fn=<NllLossBackward0>)\n",
      "13 tensor([[-1.2566, -3.2290, -0.6576, -1.8471]], grad_fn=<LogSoftmaxBackward0>) tensor(1.8471, grad_fn=<NllLossBackward0>)\n",
      "14 tensor([[-1.4233, -1.6591, -1.2192, -1.2971]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
      "15 tensor([[-1.9406, -4.0624, -2.8398, -0.2475]], grad_fn=<LogSoftmaxBackward0>) tensor(0.2475, grad_fn=<NllLossBackward0>)\n",
      "16 tensor([[-1.8998, -2.8006, -2.0584, -0.4125]], grad_fn=<LogSoftmaxBackward0>) tensor(2.0584, grad_fn=<NllLossBackward0>)\n",
      "17 tensor([[-1.3594, -1.5793, -1.3010, -1.3288]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5793, grad_fn=<NllLossBackward0>)\n",
      "18 tensor([[-3.1935, -6.2164, -0.1304, -2.5354]], grad_fn=<LogSoftmaxBackward0>) tensor(2.5354, grad_fn=<NllLossBackward0>)\n",
      "19 tensor([[-2.0984, -2.2341, -1.1180, -0.8135]], grad_fn=<LogSoftmaxBackward0>) tensor(0.8135, grad_fn=<NllLossBackward0>)\n",
      "20 tensor([[-1.2891, -1.6603, -1.3734, -1.2689]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3734, grad_fn=<NllLossBackward0>)\n",
      "21 tensor([[-1.3740, -1.5918, -1.2746, -1.3325]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2746, grad_fn=<NllLossBackward0>)\n",
      "22 tensor([[-1.5908, -1.8041, -1.2680, -1.0492]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
      "23 tensor([[-5.6286e+01, -8.5789e+01, -1.1921e-07, -1.5940e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(85.7889, grad_fn=<NllLossBackward0>)\n",
      "24 tensor([[-8.5472, -1.9583, -9.2891, -0.1524]], grad_fn=<LogSoftmaxBackward0>) tensor(8.5472, grad_fn=<NllLossBackward0>)\n",
      "25 tensor([[-1.3645, -1.4611, -1.3508, -1.3724]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4611, grad_fn=<NllLossBackward0>)\n",
      "26 tensor([[-1.3688, -1.4423, -1.3622, -1.3740]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3622, grad_fn=<NllLossBackward0>)\n",
      "27 tensor([[-1.3605, -1.4561, -1.3622, -1.3695]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3622, grad_fn=<NllLossBackward0>)\n",
      "28 tensor([[-1.3567, -1.4631, -1.3424, -1.3873]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4631, grad_fn=<NllLossBackward0>)\n",
      "29 tensor([[-1.3493, -1.4565, -1.3589, -1.3839]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3493, grad_fn=<NllLossBackward0>)\n",
      "30 tensor([[-1.3588, -1.4527, -1.3795, -1.3573]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3795, grad_fn=<NllLossBackward0>)\n",
      "31 tensor([[-2.2884, -0.1629, -5.7077, -3.0890]], grad_fn=<LogSoftmaxBackward0>) tensor(5.7077, grad_fn=<NllLossBackward0>)\n",
      "32 tensor([[-1.3631, -1.4542, -1.3234, -1.4092]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4092, grad_fn=<NllLossBackward0>)\n",
      "33 tensor([[-1.3744, -1.3896, -1.4074, -1.3741]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4074, grad_fn=<NllLossBackward0>)\n",
      "34 tensor([[-1.7142, -0.5885, -3.0141, -1.5342]], grad_fn=<LogSoftmaxBackward0>) tensor(3.0141, grad_fn=<NllLossBackward0>)\n",
      "35 tensor([[-1.3730, -1.4636, -1.3411, -1.3716]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3411, grad_fn=<NllLossBackward0>)\n",
      "36 tensor([[-1.3663, -1.4833, -1.3256, -1.3767]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3767, grad_fn=<NllLossBackward0>)\n",
      "37 tensor([[-1.3408, -1.4802, -1.3507, -1.3796]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3796, grad_fn=<NllLossBackward0>)\n",
      "38 tensor([[-1.3654, -1.4744, -1.3362, -1.3745]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4744, grad_fn=<NllLossBackward0>)\n",
      "39 tensor([[-1.3675, -1.4780, -1.3208, -1.3853]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3208, grad_fn=<NllLossBackward0>)\n",
      "40 tensor([[-1.3767, -1.3723, -1.4381, -1.3599]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3599, grad_fn=<NllLossBackward0>)\n",
      "41 tensor([[-1.3696, -1.4701, -1.3311, -1.3796]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4701, grad_fn=<NllLossBackward0>)\n",
      "42 tensor([[-1.3416, -1.5029, -1.3905, -1.3199]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3905, grad_fn=<NllLossBackward0>)\n",
      "43 tensor([[-1.3292, -1.5111, -1.3530, -1.3618]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3618, grad_fn=<NllLossBackward0>)\n",
      "44 tensor([[-1.3688, -1.4654, -1.3284, -1.3875]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3284, grad_fn=<NllLossBackward0>)\n",
      "45 tensor([[-1.3700, -1.4574, -1.3295, -1.3925]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4574, grad_fn=<NllLossBackward0>)\n",
      "46 tensor([[-1.3639, -1.4677, -1.3409, -1.3773]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4677, grad_fn=<NllLossBackward0>)\n",
      "47 tensor([[-1.3451, -1.4561, -1.3390, -1.4097]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3390, grad_fn=<NllLossBackward0>)\n",
      "48 tensor([[-1.3726, -1.4769, -1.3244, -1.3774]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3726, grad_fn=<NllLossBackward0>)\n",
      "49 tensor([[-1.3696, -1.4648, -1.3243, -1.3917]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3917, grad_fn=<NllLossBackward0>)\n",
      "50 tensor([[-1.3724, -1.4443, -1.3545, -1.3763]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3724, grad_fn=<NllLossBackward0>)\n",
      "51 tensor([[-1.3888, -1.1914, -1.6899, -1.3384]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
      "52 tensor([[-1.3694, -1.4683, -1.3277, -1.3849]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3694, grad_fn=<NllLossBackward0>)\n",
      "53 tensor([[-1.3912, -1.4494, -1.3358, -1.3722]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3912, grad_fn=<NllLossBackward0>)\n",
      "54 tensor([[-1.3819, -1.5845, -1.2779, -1.3273]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2779, grad_fn=<NllLossBackward0>)\n",
      "55 tensor([[-1.3716, -1.4576, -1.3457, -1.3738]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4576, grad_fn=<NllLossBackward0>)\n",
      "56 tensor([[-1.3684, -1.4744, -1.3331, -1.3748]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3331, grad_fn=<NllLossBackward0>)\n",
      "57 tensor([[-1.3701, -1.4381, -1.3658, -1.3729]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3701, grad_fn=<NllLossBackward0>)\n",
      "58 tensor([[-1.4549, -1.2794, -1.5321, -1.3009]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3009, grad_fn=<NllLossBackward0>)\n",
      "59 tensor([[-1.3683, -1.4366, -1.3776, -1.3644]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3644, grad_fn=<NllLossBackward0>)\n",
      "60 tensor([[-1.3768, -1.4463, -1.3498, -1.3749]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3768, grad_fn=<NllLossBackward0>)\n",
      "61 tensor([[-1.3698, -1.4532, -1.3534, -1.3717]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4532, grad_fn=<NllLossBackward0>)\n",
      "62 tensor([[-1.3666, -1.4335, -1.3790, -1.3675]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3790, grad_fn=<NllLossBackward0>)\n",
      "63 tensor([[-1.3830, -1.4837, -1.3274, -1.3579]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3274, grad_fn=<NllLossBackward0>)\n",
      "64 tensor([[-1.4050, -1.4169, -1.5061, -1.2364]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2364, grad_fn=<NllLossBackward0>)\n",
      "65 tensor([[-1.3664, -1.4783, -1.3215, -1.3853]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3664, grad_fn=<NllLossBackward0>)\n",
      "66 tensor([[-1.3774, -1.4816, -1.2962, -1.3987]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3987, grad_fn=<NllLossBackward0>)\n",
      "67 tensor([[-1.3764, -1.4508, -1.2938, -1.4316]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4316, grad_fn=<NllLossBackward0>)\n",
      "68 tensor([[-1.3729, -1.4664, -1.3440, -1.3662]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3729, grad_fn=<NllLossBackward0>)\n",
      "69 tensor([[-3.9540, -0.0881, -7.0955, -2.7431]], grad_fn=<LogSoftmaxBackward0>) tensor(3.9540, grad_fn=<NllLossBackward0>)\n",
      "70 tensor([[-1.3698, -1.4591, -1.3389, -1.3813]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3389, grad_fn=<NllLossBackward0>)\n",
      "71 tensor([[-1.3876, -1.4964, -1.3092, -1.3612]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3612, grad_fn=<NllLossBackward0>)\n",
      "72 tensor([[-1.3592, -1.4808, -1.3382, -1.3730]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4808, grad_fn=<NllLossBackward0>)\n",
      "73 tensor([[-0.4102, -2.7572, -2.1450, -1.8584]], grad_fn=<LogSoftmaxBackward0>) tensor(0.4102, grad_fn=<NllLossBackward0>)\n",
      "74 tensor([[-1.2616, -1.6187, -1.3353, -1.3643]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3353, grad_fn=<NllLossBackward0>)\n",
      "75 tensor([[-1.3554, -1.4931, -1.3199, -1.3850]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4931, grad_fn=<NllLossBackward0>)\n",
      "76 tensor([[-1.3707, -1.4742, -1.3275, -1.3785]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4742, grad_fn=<NllLossBackward0>)\n",
      "77 tensor([[-1.3662, -1.4868, -1.3267, -1.3724]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4868, grad_fn=<NllLossBackward0>)\n",
      "78 tensor([[-1.0757, -1.9426, -1.1274, -1.6516]], grad_fn=<LogSoftmaxBackward0>) tensor(1.6516, grad_fn=<NllLossBackward0>)\n",
      "79 tensor([[-1.3666, -1.4735, -1.3416, -1.3685]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4735, grad_fn=<NllLossBackward0>)\n",
      "80 tensor([[-1.3723, -1.4616, -1.3544, -1.3606]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3723, grad_fn=<NllLossBackward0>)\n",
      "81 tensor([[-1.2621, -1.6303, -1.2668, -1.4299]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4299, grad_fn=<NllLossBackward0>)\n",
      "82 tensor([[-1.3029, -1.6370, -1.5198, -1.1553]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1553, grad_fn=<NllLossBackward0>)\n",
      "83 tensor([[-1.2013, -1.6692, -1.4930, -1.2514]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2514, grad_fn=<NllLossBackward0>)\n",
      "84 tensor([[-1.3725, -1.4742, -1.3335, -1.3704]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4742, grad_fn=<NllLossBackward0>)\n",
      "85 tensor([[-1.2234, -1.5747, -1.3718, -1.4063]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3718, grad_fn=<NllLossBackward0>)\n",
      "86 tensor([[-1.3019, -1.5147, -1.4094, -1.3325]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3325, grad_fn=<NllLossBackward0>)\n",
      "87 tensor([[-1.3596, -1.4560, -1.3540, -1.3789]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3596, grad_fn=<NllLossBackward0>)\n",
      "88 tensor([[-1.3532, -1.4750, -1.3454, -1.3769]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4750, grad_fn=<NllLossBackward0>)\n",
      "89 tensor([[-1.3259, -1.2837, -1.6284, -1.3425]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3425, grad_fn=<NllLossBackward0>)\n",
      "90 tensor([[-1.2264, -1.5048, -1.4644, -1.3729]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5048, grad_fn=<NllLossBackward0>)\n",
      "91 tensor([[-1.3585, -1.5328, -1.3221, -1.3453]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3453, grad_fn=<NllLossBackward0>)\n",
      "92 tensor([[-1.3717, -1.4774, -1.3653, -1.3364]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3364, grad_fn=<NllLossBackward0>)\n",
      "93 tensor([[-1.3247, -0.9627, -2.0939, -1.4739]], grad_fn=<LogSoftmaxBackward0>) tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "94 tensor([[-1.3834, -1.4493, -1.3391, -1.3765]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4493, grad_fn=<NllLossBackward0>)\n",
      "95 tensor([[-0.7104, -1.7058, -2.9722, -1.2883]], grad_fn=<LogSoftmaxBackward0>) tensor(2.9722, grad_fn=<NllLossBackward0>)\n",
      "96 tensor([[-1.3857, -1.4337, -1.3497, -1.3779]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4337, grad_fn=<NllLossBackward0>)\n",
      "97 tensor([[-1.3293, -1.6372, -1.6201, -1.0702]], grad_fn=<LogSoftmaxBackward0>) tensor(1.0702, grad_fn=<NllLossBackward0>)\n",
      "98 tensor([[-1.3416, -2.6933, -0.8167, -1.4739]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4739, grad_fn=<NllLossBackward0>)\n",
      "99 tensor([[-2.2725, -2.4364, -1.4552, -0.5515]], grad_fn=<LogSoftmaxBackward0>) tensor(0.5515, grad_fn=<NllLossBackward0>)\n",
      "100 tensor([[-1.3712, -1.4840, -1.3396, -1.3567]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4840, grad_fn=<NllLossBackward0>)\n",
      "101 tensor([[-1.7018, -2.8082, -1.6508, -0.5702]], grad_fn=<LogSoftmaxBackward0>) tensor(0.5702, grad_fn=<NllLossBackward0>)\n",
      "102 tensor([[-1.3794, -1.4616, -1.3431, -1.3651]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4616, grad_fn=<NllLossBackward0>)\n",
      "103 tensor([[-1.4898, -1.9645, -1.1913, -1.1070]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1913, grad_fn=<NllLossBackward0>)\n",
      "104 tensor([[-1.4942, -1.5896, -1.3187, -1.1904]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3187, grad_fn=<NllLossBackward0>)\n",
      "105 tensor([[-1.4575, -1.6539, -1.4133, -1.1010]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4133, grad_fn=<NllLossBackward0>)\n",
      "106 tensor([[-5.5182e+00, -6.5091e+00, -6.7414e+00, -6.7063e-03]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(6.7414, grad_fn=<NllLossBackward0>)\n",
      "107 tensor([[-1.4974, -1.5700, -1.0999, -1.4467]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4467, grad_fn=<NllLossBackward0>)\n",
      "108 tensor([[-1.7232, -1.4582, -1.3648, -1.0984]], grad_fn=<LogSoftmaxBackward0>) tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "109 tensor([[-7.3381e+00, -6.5127e-04, -2.2666e+01, -1.4046e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(22.6663, grad_fn=<NllLossBackward0>)\n",
      "110 tensor([[-1.3402, -1.7739, -1.0847, -1.4673]], grad_fn=<LogSoftmaxBackward0>) tensor(1.0847, grad_fn=<NllLossBackward0>)\n",
      "111 tensor([[-1.3854, -1.4860, -1.3122, -1.3693]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4860, grad_fn=<NllLossBackward0>)\n",
      "112 tensor([[-2.1265, -3.0048, -0.4739, -1.5671]], grad_fn=<LogSoftmaxBackward0>) tensor(0.4739, grad_fn=<NllLossBackward0>)\n",
      "113 tensor([[-2.2249e+01, -1.7815e+01, -5.8888e-05, -9.7402e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(9.7402, grad_fn=<NllLossBackward0>)\n",
      "114 tensor([[-4.3047, -3.5460, -6.7899, -0.0444]], grad_fn=<LogSoftmaxBackward0>) tensor(0.0444, grad_fn=<NllLossBackward0>)\n",
      "115 tensor([[-1.4034, -1.4442, -1.3445, -1.3562]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4442, grad_fn=<NllLossBackward0>)\n",
      "116 tensor([[-1.3608, -1.4863, -1.3656, -1.3389]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4863, grad_fn=<NllLossBackward0>)\n",
      "117 tensor([[-1.3288, -3.1086, -1.2533, -0.9040]], grad_fn=<LogSoftmaxBackward0>) tensor(0.9040, grad_fn=<NllLossBackward0>)\n",
      "118 tensor([[-1.2808, -1.5565, -2.0004, -0.9781]], grad_fn=<LogSoftmaxBackward0>) tensor(2.0004, grad_fn=<NllLossBackward0>)\n",
      "119 tensor([[  0.0000, -57.8631, -37.9586, -27.7437]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(37.9586, grad_fn=<NllLossBackward0>)\n",
      "120 tensor([[-2.8846, -4.6284, -0.1854, -2.2671]], grad_fn=<LogSoftmaxBackward0>) tensor(0.1854, grad_fn=<NllLossBackward0>)\n",
      "121 tensor([[-1.4021, -1.4904, -1.2995, -1.3627]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4904, grad_fn=<NllLossBackward0>)\n",
      "122 tensor([[-1.4195, -1.4790, -1.2905, -1.3658]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4195, grad_fn=<NllLossBackward0>)\n",
      "123 tensor([[-1.4291, -1.4393, -1.3210, -1.3606]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4291, grad_fn=<NllLossBackward0>)\n",
      "124 tensor([[-3.6304, -2.9363, -0.1878, -2.3897]], grad_fn=<LogSoftmaxBackward0>) tensor(0.1878, grad_fn=<NllLossBackward0>)\n",
      "125 tensor([[-2.4833, -2.9473, -0.4346, -1.5301]], grad_fn=<LogSoftmaxBackward0>) tensor(2.9473, grad_fn=<NllLossBackward0>)\n",
      "126 tensor([[ -4.8363, -13.9757,  -0.0551,  -3.0869]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0.0551, grad_fn=<NllLossBackward0>)\n",
      "127 tensor([[-1.3935, -1.4606, -1.3267, -1.3691]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4606, grad_fn=<NllLossBackward0>)\n",
      "128 tensor([[-1.4858, -1.5957, -1.1876, -1.3244]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3244, grad_fn=<NllLossBackward0>)\n",
      "Train accuracy: 0.29457364341085274\n",
      "[[ 0  0 19  0]\n",
      " [ 0  0 30  0]\n",
      " [ 0  0 38  0]\n",
      " [ 0  0 42  0]]\n",
      "Test accuracy: 0.29545454545454547\n",
      "[[ 0  0  5  0]\n",
      " [ 0  0 15  0]\n",
      " [ 0  0 13  0]\n",
      " [ 0  0 11  0]]\n",
      "Time: 490.73017024993896\n",
      "----\n",
      "Random state: 6\n",
      "0 tensor([[-1.3208, -1.3922, -1.3823, -1.4544]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3922, grad_fn=<NllLossBackward0>)\n",
      "1 tensor([[-1.2799, -1.3830, -1.3000, -1.6165]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
      "2 tensor([[-1.3521, -1.3691, -1.3583, -1.4702]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3521, grad_fn=<NllLossBackward0>)\n",
      "3 tensor([[-2.3608, -1.0746, -0.8967, -1.8560]], grad_fn=<LogSoftmaxBackward0>) tensor(0.8967, grad_fn=<NllLossBackward0>)\n",
      "4 tensor([[-1.4285, -1.3807, -1.0963, -1.7439]], grad_fn=<LogSoftmaxBackward0>) tensor(1.0963, grad_fn=<NllLossBackward0>)\n",
      "5 tensor([[-1.3762, -1.3866, -1.2819, -1.5140]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2819, grad_fn=<NllLossBackward0>)\n",
      "6 tensor([[-1.3285, -1.4101, -1.3459, -1.4666]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4101, grad_fn=<NllLossBackward0>)\n",
      "7 tensor([[-1.5362, -1.4975, -0.9098, -1.8420]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5362, grad_fn=<NllLossBackward0>)\n",
      "8 tensor([[-3.0258, -0.9333, -0.6412, -3.4551]], grad_fn=<LogSoftmaxBackward0>) tensor(3.4551, grad_fn=<NllLossBackward0>)\n",
      "9 tensor([[-1.3720, -1.5171, -1.3131, -1.3545]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3131, grad_fn=<NllLossBackward0>)\n",
      "10 tensor([[-1.3311, -1.4061, -1.3458, -1.4680]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4061, grad_fn=<NllLossBackward0>)\n",
      "11 tensor([[-1.4067, -1.4390, -1.1955, -1.5356]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4067, grad_fn=<NllLossBackward0>)\n",
      "12 tensor([[-1.5323, -2.0704, -0.6522, -1.9883]], grad_fn=<LogSoftmaxBackward0>) tensor(0.6522, grad_fn=<NllLossBackward0>)\n",
      "13 tensor([[-1.3450, -1.4796, -1.3263, -1.4014]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3450, grad_fn=<NllLossBackward0>)\n",
      "14 tensor([[-5.0096, -3.2913, -0.0493, -5.4652]], grad_fn=<LogSoftmaxBackward0>) tensor(0.0493, grad_fn=<NllLossBackward0>)\n",
      "15 tensor([[-1.3246, -1.3979, -1.4118, -1.4136]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3979, grad_fn=<NllLossBackward0>)\n",
      "16 tensor([[-1.3817, -1.4405, -1.3149, -1.4124]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3817, grad_fn=<NllLossBackward0>)\n",
      "17 tensor([[-37.5242, -29.7346,   0.0000, -40.0928]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(0., grad_fn=<NllLossBackward0>)\n",
      "18 tensor([[-1.9980, -7.8511, -0.1517, -5.3563]], grad_fn=<LogSoftmaxBackward0>) tensor(5.3563, grad_fn=<NllLossBackward0>)\n",
      "19 tensor([[-1.3550, -1.4706, -1.5403, -1.2108]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5403, grad_fn=<NllLossBackward0>)\n",
      "20 tensor([[-1.3026, -1.5806, -1.3817, -1.3050]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3817, grad_fn=<NllLossBackward0>)\n",
      "21 tensor([[-8.5356e+00, -7.9799e+00, -8.0366e+00, -8.6235e-04]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(8.0366, grad_fn=<NllLossBackward0>)\n",
      "22 tensor([[-1.3534, -1.4053, -1.3569, -1.4318]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3534, grad_fn=<NllLossBackward0>)\n",
      "23 tensor([[-1.4116, -1.4150, -1.3560, -1.3641]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3641, grad_fn=<NllLossBackward0>)\n",
      "24 tensor([[-1.3335, -1.4115, -1.3486, -1.4563]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4115, grad_fn=<NllLossBackward0>)\n",
      "25 tensor([[-1.3799, -1.3996, -1.3716, -1.3944]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3716, grad_fn=<NllLossBackward0>)\n",
      "26 tensor([[-1.3324, -1.4156, -1.3414, -1.4616]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4156, grad_fn=<NllLossBackward0>)\n",
      "27 tensor([[-1.3438, -1.4081, -1.3389, -1.4592]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4081, grad_fn=<NllLossBackward0>)\n",
      "28 tensor([[-1.3760, -1.4374, -1.3391, -1.3952]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3391, grad_fn=<NllLossBackward0>)\n",
      "29 tensor([[-1.4196, -1.3952, -1.2712, -1.4700]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3952, grad_fn=<NllLossBackward0>)\n",
      "30 tensor([[-1.7001, -1.9691, -2.0791, -0.5929]], grad_fn=<LogSoftmaxBackward0>) tensor(0.5929, grad_fn=<NllLossBackward0>)\n",
      "31 tensor([[-2.5794, -1.4053, -0.6541, -1.8391]], grad_fn=<LogSoftmaxBackward0>) tensor(1.8391, grad_fn=<NllLossBackward0>)\n",
      "32 tensor([[-2.0886, -1.4943, -1.1207, -1.1219]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1219, grad_fn=<NllLossBackward0>)\n",
      "33 tensor([[-1.9038, -1.6255, -1.2751, -0.9814]], grad_fn=<LogSoftmaxBackward0>) tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "34 tensor([[-1.3583, -1.4080, -1.3567, -1.4240]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3583, grad_fn=<NllLossBackward0>)\n",
      "35 tensor([[-1.3458, -1.4164, -1.3635, -1.4216]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4164, grad_fn=<NllLossBackward0>)\n",
      "36 tensor([[-1.3976, -1.4786, -1.3641, -1.3122]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3641, grad_fn=<NllLossBackward0>)\n",
      "37 tensor([[-1.4323, -1.4225, -1.3967, -1.2993]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2993, grad_fn=<NllLossBackward0>)\n",
      "38 tensor([[-1.3491, -1.3983, -1.3795, -1.4195]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3983, grad_fn=<NllLossBackward0>)\n",
      "39 tensor([[-1.5188, -1.5527, -1.0889, -1.4577]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4577, grad_fn=<NllLossBackward0>)\n",
      "40 tensor([[-8.6478e+00, -7.0607e+00, -9.4802e+00, -1.1107e-03]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(9.4802, grad_fn=<NllLossBackward0>)\n",
      "41 tensor([[-1.3770, -1.4477, -1.3454, -1.3778]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3454, grad_fn=<NllLossBackward0>)\n",
      "42 tensor([[-1.3600, -1.4450, -1.3588, -1.3838]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3600, grad_fn=<NllLossBackward0>)\n",
      "43 tensor([[-1.3560, -1.3964, -1.3153, -1.4852]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4852, grad_fn=<NllLossBackward0>)\n",
      "44 tensor([[-1.3309, -1.4019, -1.3808, -1.4344]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3309, grad_fn=<NllLossBackward0>)\n",
      "45 tensor([[-1.3261, -1.4177, -1.3698, -1.4351]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4177, grad_fn=<NllLossBackward0>)\n",
      "46 tensor([[-1.7923, -1.1831, -1.0428, -1.7450]], grad_fn=<LogSoftmaxBackward0>) tensor(1.0428, grad_fn=<NllLossBackward0>)\n",
      "47 tensor([[-1.3644, -1.4020, -1.3057, -1.4812]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3057, grad_fn=<NllLossBackward0>)\n",
      "48 tensor([[-1.3565, -1.4087, -1.3256, -1.4596]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3256, grad_fn=<NllLossBackward0>)\n",
      "49 tensor([[-1.4821, -1.3670, -1.0547, -1.7738]], grad_fn=<LogSoftmaxBackward0>) tensor(1.7738, grad_fn=<NllLossBackward0>)\n",
      "50 tensor([[-1.3423, -1.4124, -1.3439, -1.4509]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4509, grad_fn=<NllLossBackward0>)\n",
      "51 tensor([[-1.3369, -1.4158, -1.3519, -1.4445]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4445, grad_fn=<NllLossBackward0>)\n",
      "52 tensor([[-1.6951, -1.3224, -1.1246, -1.4910]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4910, grad_fn=<NllLossBackward0>)\n",
      "53 tensor([[-1.3371, -1.4194, -1.3404, -1.4533]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4194, grad_fn=<NllLossBackward0>)\n",
      "54 tensor([[-2.8967, -2.0244, -0.5152, -1.5355]], grad_fn=<LogSoftmaxBackward0>) tensor(0.5152, grad_fn=<NllLossBackward0>)\n",
      "55 tensor([[-1.6286, -1.4354, -1.0962, -1.4625]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4625, grad_fn=<NllLossBackward0>)\n",
      "56 tensor([[-1.3654, -1.4058, -1.3030, -1.4791]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4791, grad_fn=<NllLossBackward0>)\n",
      "57 tensor([[-1.6283, -1.3934, -1.1414, -1.4434]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4434, grad_fn=<NllLossBackward0>)\n",
      "58 tensor([[-3.9753, -2.5098, -0.2252, -2.2867]], grad_fn=<LogSoftmaxBackward0>) tensor(0.2252, grad_fn=<NllLossBackward0>)\n",
      "59 tensor([[-1.6405, -1.5841, -1.0826, -1.3384]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
      "60 tensor([[-1.3516, -1.4141, -1.3428, -1.4400]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3516, grad_fn=<NllLossBackward0>)\n",
      "61 tensor([[-1.5533, -1.9262, -0.8157, -1.6073]], grad_fn=<LogSoftmaxBackward0>) tensor(1.6073, grad_fn=<NllLossBackward0>)\n",
      "62 tensor([[-1.5482, -1.5571, -1.1355, -1.3652]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3652, grad_fn=<NllLossBackward0>)\n",
      "63 tensor([[-1.3356, -1.4004, -1.3540, -1.4598]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3356, grad_fn=<NllLossBackward0>)\n",
      "64 tensor([[-1.3328, -1.4212, -1.3550, -1.4402]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4212, grad_fn=<NllLossBackward0>)\n",
      "65 tensor([[-1.3356, -1.4306, -1.3456, -1.4377]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3456, grad_fn=<NllLossBackward0>)\n",
      "66 tensor([[-1.6784, -1.5968, -0.9078, -1.5732]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5732, grad_fn=<NllLossBackward0>)\n",
      "67 tensor([[-1.8685, -1.6695, -1.0842, -1.1422]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1422, grad_fn=<NllLossBackward0>)\n",
      "68 tensor([[-2.1521, -1.3824, -0.8999, -1.4864]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4864, grad_fn=<NllLossBackward0>)\n",
      "69 tensor([[-1.3618, -1.4386, -1.3583, -1.3885]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3583, grad_fn=<NllLossBackward0>)\n",
      "70 tensor([[-1.3282, -1.4153, -1.3719, -1.4330]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4153, grad_fn=<NllLossBackward0>)\n",
      "71 tensor([[-1.3319, -1.4327, -1.3573, -1.4271]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4327, grad_fn=<NllLossBackward0>)\n",
      "72 tensor([[-1.6519, -1.5652, -1.2558, -1.1570]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1570, grad_fn=<NllLossBackward0>)\n",
      "73 tensor([[-1.3361, -1.4059, -1.3715, -1.4343]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4059, grad_fn=<NllLossBackward0>)\n",
      "74 tensor([[-1.4453, -1.6024, -1.3796, -1.1672]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4453, grad_fn=<NllLossBackward0>)\n",
      "75 tensor([[-1.5311, -1.7410, -1.2567, -1.1277]], grad_fn=<LogSoftmaxBackward0>) tensor(1.1277, grad_fn=<NllLossBackward0>)\n",
      "76 tensor([[-1.3397, -1.4270, -1.3746, -1.4061]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4270, grad_fn=<NllLossBackward0>)\n",
      "77 tensor([[-1.3285, -1.4214, -1.3808, -1.4174]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4214, grad_fn=<NllLossBackward0>)\n",
      "78 tensor([[-1.3368, -1.4132, -1.3829, -1.4142]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4132, grad_fn=<NllLossBackward0>)\n",
      "79 tensor([[-1.3703, -1.4305, -1.3616, -1.3843]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3616, grad_fn=<NllLossBackward0>)\n",
      "80 tensor([[-1.3683, -1.4365, -1.3632, -1.3790]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3790, grad_fn=<NllLossBackward0>)\n",
      "81 tensor([[-1.3389, -1.4046, -1.3833, -1.4203]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4046, grad_fn=<NllLossBackward0>)\n",
      "82 tensor([[-1.3384, -1.4068, -1.3784, -1.4236]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3384, grad_fn=<NllLossBackward0>)\n",
      "83 tensor([[-1.3274, -1.4250, -1.3835, -1.4122]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4250, grad_fn=<NllLossBackward0>)\n",
      "84 tensor([[-1.4867, -1.4936, -1.3946, -1.1994]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3946, grad_fn=<NllLossBackward0>)\n",
      "85 tensor([[-1.7491, -1.8198, -1.4542, -0.8430]], grad_fn=<LogSoftmaxBackward0>) tensor(0.8430, grad_fn=<NllLossBackward0>)\n",
      "86 tensor([[-1.5842, -1.8473, -1.1180, -1.1702]], grad_fn=<LogSoftmaxBackward0>) tensor(1.8473, grad_fn=<NllLossBackward0>)\n",
      "87 tensor([[-1.3540, -1.3917, -1.3722, -1.4288]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3540, grad_fn=<NllLossBackward0>)\n",
      "88 tensor([[-4.2090, -3.4659, -1.3504, -0.3642]], grad_fn=<LogSoftmaxBackward0>) tensor(0.3642, grad_fn=<NllLossBackward0>)\n",
      "89 tensor([[-9.2623, -6.4572, -2.2103, -0.1180]], grad_fn=<LogSoftmaxBackward0>) tensor(2.2103, grad_fn=<NllLossBackward0>)\n",
      "90 tensor([[-1.3561, -1.3994, -1.3423, -1.4510]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3994, grad_fn=<NllLossBackward0>)\n",
      "91 tensor([[-6.3798, -5.5241, -0.0073, -6.4539]], grad_fn=<LogSoftmaxBackward0>) tensor(0.0073, grad_fn=<NllLossBackward0>)\n",
      "92 tensor([[-4.7614, -2.7382, -0.1274, -3.0712]], grad_fn=<LogSoftmaxBackward0>) tensor(0.1274, grad_fn=<NllLossBackward0>)\n",
      "93 tensor([[-1.0193e+01, -7.1598e+00, -8.2721e-04, -1.1305e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(11.3047, grad_fn=<NllLossBackward0>)\n",
      "94 tensor([[-1.3353, -1.4027, -1.3709, -1.4392]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4027, grad_fn=<NllLossBackward0>)\n",
      "95 tensor([[-1.7926, -1.6508, -0.9351, -1.3902]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3902, grad_fn=<NllLossBackward0>)\n",
      "96 tensor([[-1.3446, -1.4021, -1.3641, -1.4369]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4021, grad_fn=<NllLossBackward0>)\n",
      "97 tensor([[-1.3454, -1.3966, -1.3736, -1.4315]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3966, grad_fn=<NllLossBackward0>)\n",
      "98 tensor([[-1.3476, -1.3989, -1.3634, -1.4378]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3989, grad_fn=<NllLossBackward0>)\n",
      "99 tensor([[-1.4100, -1.4528, -1.3228, -1.3643]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3643, grad_fn=<NllLossBackward0>)\n",
      "100 tensor([[-1.3941, -1.4420, -1.7839, -1.0570]], grad_fn=<LogSoftmaxBackward0>) tensor(1.7839, grad_fn=<NllLossBackward0>)\n",
      "101 tensor([[-1.3886, -1.4517, -1.6907, -1.1026]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4517, grad_fn=<NllLossBackward0>)\n",
      "102 tensor([[-1.3462, -1.3968, -1.3776, -1.4262]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3968, grad_fn=<NllLossBackward0>)\n",
      "103 tensor([[-1.8834, -1.7561, -1.6700, -0.7196]], grad_fn=<LogSoftmaxBackward0>) tensor(0.7196, grad_fn=<NllLossBackward0>)\n",
      "104 tensor([[-1.9305, -1.8075, -1.1427, -0.9891]], grad_fn=<LogSoftmaxBackward0>) tensor(0.9891, grad_fn=<NllLossBackward0>)\n",
      "105 tensor([[-2.1236, -2.2712, -1.9886, -0.4458]], grad_fn=<LogSoftmaxBackward0>) tensor(0.4458, grad_fn=<NllLossBackward0>)\n",
      "106 tensor([[-1.4264, -1.4644, -1.4037, -1.2627]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
      "107 tensor([[-7.9543, -4.5908, -0.0210, -4.5788]], grad_fn=<LogSoftmaxBackward0>) tensor(0.0210, grad_fn=<NllLossBackward0>)\n",
      "108 tensor([[-2.6428, -1.5914, -0.6091, -1.7073]], grad_fn=<LogSoftmaxBackward0>) tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
      "109 tensor([[-1.3435, -1.4046, -1.3823, -1.4164]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3435, grad_fn=<NllLossBackward0>)\n",
      "110 tensor([[-1.5969, -1.4533, -1.2649, -1.2680]], grad_fn=<LogSoftmaxBackward0>) tensor(1.2680, grad_fn=<NllLossBackward0>)\n",
      "111 tensor([[-2.0486, -2.0720, -1.2799, -0.7612]], grad_fn=<LogSoftmaxBackward0>) tensor(0.7612, grad_fn=<NllLossBackward0>)\n",
      "112 tensor([[-1.3504, -1.3825, -1.3851, -1.4287]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3825, grad_fn=<NllLossBackward0>)\n",
      "113 tensor([[-1.4365, -1.9459, -1.5103, -0.9200]], grad_fn=<LogSoftmaxBackward0>) tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "114 tensor([[-1.3902, -1.4050, -1.3604, -1.3901]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3902, grad_fn=<NllLossBackward0>)\n",
      "115 tensor([[-1.4894, -1.5283, -1.4885, -1.1029]], grad_fn=<LogSoftmaxBackward0>) tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "116 tensor([[-4.9985, -2.1943, -0.1504, -3.8432]], grad_fn=<LogSoftmaxBackward0>) tensor(0.1504, grad_fn=<NllLossBackward0>)\n",
      "117 tensor([[-1.3523, -1.4682, -1.4148, -1.3167]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4682, grad_fn=<NllLossBackward0>)\n",
      "118 tensor([[-1.4632, -1.5677, -1.3731, -1.1820]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3731, grad_fn=<NllLossBackward0>)\n",
      "119 tensor([[-1.6216, -2.6479, -2.1774, -0.4808]], grad_fn=<LogSoftmaxBackward0>) tensor(2.1774, grad_fn=<NllLossBackward0>)\n",
      "120 tensor([[-1.3902, -1.5967, -1.4917, -1.1287]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3902, grad_fn=<NllLossBackward0>)\n",
      "121 tensor([[-1.3642, -1.3841, -1.3548, -1.4445]], grad_fn=<LogSoftmaxBackward0>) tensor(1.3841, grad_fn=<NllLossBackward0>)\n",
      "122 tensor([[-94.3709, -23.8732,   0.0000, -41.7971]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(23.8732, grad_fn=<NllLossBackward0>)\n",
      "123 tensor([[-2.0114, -0.7098, -2.3399, -1.2797]], grad_fn=<LogSoftmaxBackward0>) tensor(2.3399, grad_fn=<NllLossBackward0>)\n",
      "124 tensor([[-1.1855, -0.5980, -2.9751, -2.3704]], grad_fn=<LogSoftmaxBackward0>) tensor(2.3704, grad_fn=<NllLossBackward0>)\n",
      "125 tensor([[-1.5868, -0.8919, -1.9803, -1.3962]], grad_fn=<LogSoftmaxBackward0>) tensor(1.9803, grad_fn=<NllLossBackward0>)\n",
      "126 tensor([[-8.6013e+00, -8.0345e-03, -1.8750e+01, -4.8513e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(18.7495, grad_fn=<NllLossBackward0>)\n",
      "127 tensor([[-8.6531e+00, -3.7103e-04, -1.7743e+01, -8.5355e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>) tensor(17.7428, grad_fn=<NllLossBackward0>)\n",
      "128 tensor([[-1.3541, -1.3457, -1.4180, -1.4302]], grad_fn=<LogSoftmaxBackward0>) tensor(1.4302, grad_fn=<NllLossBackward0>)\n",
      "Train accuracy: 0.24031007751937986\n",
      "[[15  0  2  0]\n",
      " [32  2  0  0]\n",
      " [11 18  6  3]\n",
      " [13 19  0  8]]\n",
      "Test accuracy: 0.22727272727272727\n",
      "[[ 3  2  1  1]\n",
      " [10  1  0  0]\n",
      " [ 7  2  2  2]\n",
      " [ 0  7  2  4]]\n",
      "Time: 1006.3905000686646\n",
      "----\n",
      "Mean test accuracy: 0.26136363636363635\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "acc = []\n",
    "for i in [0, 6]:\n",
    "    print('Random state:', i)\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    j = 0\n",
    "    while j < len(X_preproc):\n",
    "        if y_preproc[j][0] != 0:\n",
    "            X_data.append(torch.from_numpy(X_preproc[j]).to(device))\n",
    "            y_data.append(torch.tensor(y_preproc[j]).to(device) - 1)\n",
    "        j += 1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=i)\n",
    "    model = likan_alh()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for n in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train[n])\n",
    "        loss = F.nll_loss(output, y_train[n])\n",
    "        print(n, output, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    trainmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_train)):\n",
    "            output = model(X_train[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_train[n]).sum().item()\n",
    "            trainmat[y_train[n].item()][y_pred.item()] += 1\n",
    "    print('Train accuracy:', correct / len(y_train))\n",
    "    print(trainmat)\n",
    "    testmat = np.zeros((4, 4), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_test)):\n",
    "            output = model(X_test[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_test[n]).sum().item()\n",
    "            testmat[y_test[n].item()][y_pred.item()] += 1\n",
    "    print('Test accuracy:', correct / len(y_test))\n",
    "    print(testmat)\n",
    "    acc.append(correct / len(y_test))\n",
    "    print('Time:', time.time() - byrjun)\n",
    "    print('----')\n",
    "print('Mean test accuracy:', np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2a528-645f-43bd-83c2-51b30b91a8e4",
   "metadata": {},
   "source": [
    "Nú er málið lagað. Ef við gerum meira en eina lotu (\"epoch\"), þá fáum við betri niðurstöður. Við skulum prófa aftur með 5 lotum og öllum myndum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63c08c6a-6625-4c1c-a786-0646acb0e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e9843d7-edb2-4f84-90a6-944b32090358",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_data = []\n",
    "j = 0\n",
    "while j < len(X_preproc):\n",
    "    X_data.append(torch.from_numpy(X_preproc[j]).to(device))\n",
    "    y_data.append(torch.tensor(y_preproc[j]).to(device))\n",
    "    j += 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75bdcd89-1e2c-4878-a2df-15ec96a09980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train accuracy: 0.4607329842931937\n",
      "[[60  0  0  0  5]\n",
      " [14  0  0  2  0]\n",
      " [32  0  1  1  1]\n",
      " [18  0  1  8  5]\n",
      " [23  0  1  0 19]]\n",
      "Test accuracy: 0.359375\n",
      "[[17  0  0  0  0]\n",
      " [ 7  0  0  0  1]\n",
      " [ 9  0  0  0  1]\n",
      " [10  0  0  4  5]\n",
      " [ 8  0  0  0  2]]\n",
      "Time: 789.9530470371246\n",
      "----\n",
      "Epoch: 1\n",
      "Train accuracy: 0.4031413612565445\n",
      "[[61  0  0  1  3]\n",
      " [13  0  0  3  0]\n",
      " [33  0  0  2  0]\n",
      " [19  1  0  9  3]\n",
      " [25  1  0 10  7]]\n",
      "Test accuracy: 0.453125\n",
      "[[17  0  0  0  0]\n",
      " [ 7  0  0  1  0]\n",
      " [ 9  0  1  0  0]\n",
      " [10  1  0  8  0]\n",
      " [ 5  0  0  2  3]]\n",
      "Time: 1564.7488777637482\n",
      "----\n",
      "Epoch: 2\n",
      "Train accuracy: 0.41361256544502617\n",
      "[[64  0  0  1  0]\n",
      " [14  0  0  2  0]\n",
      " [33  1  0  1  0]\n",
      " [18  2  0 12  0]\n",
      " [26  0  0 14  3]]\n",
      "Test accuracy: 0.34375\n",
      "[[17  0  0  0  0]\n",
      " [ 7  0  0  1  0]\n",
      " [10  0  0  0  0]\n",
      " [14  0  0  4  1]\n",
      " [ 9  0  0  0  1]]\n",
      "Time: 2330.3524680137634\n",
      "----\n",
      "Epoch: 3\n",
      "Train accuracy: 0.4293193717277487\n",
      "[[63  0  1  0  1]\n",
      " [13  1  0  1  1]\n",
      " [33  0  1  1  0]\n",
      " [20  3  0  8  1]\n",
      " [28  2  1  3  9]]\n",
      "Test accuracy: 0.359375\n",
      "[[17  0  0  0  0]\n",
      " [ 7  0  1  0  0]\n",
      " [ 9  0  1  0  0]\n",
      " [12  1  1  3  2]\n",
      " [ 8  0  0  0  2]]\n",
      "Time: 3095.343735933304\n",
      "----\n",
      "Epoch: 4\n",
      "Train accuracy: 0.39267015706806285\n",
      "[[65  0  0  0  0]\n",
      " [14  1  0  1  0]\n",
      " [33  1  1  0  0]\n",
      " [18  6  0  8  0]\n",
      " [40  0  0  3  0]]\n",
      "Test accuracy: 0.375\n",
      "[[17  0  0  0  0]\n",
      " [ 7  1  0  0  0]\n",
      " [ 9  0  1  0  0]\n",
      " [11  3  0  5  0]\n",
      " [10  0  0  0  0]]\n",
      "Time: 3830.328071832657\n",
      "----\n",
      "Mean test accuracy: 0.378125\n"
     ]
    }
   ],
   "source": [
    "byrjun = time.time()\n",
    "acc = []\n",
    "for i in range(num_epochs):\n",
    "    print('Epoch:', i)\n",
    "    model = likan()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    for n in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train[n])\n",
    "        loss = F.nll_loss(output, y_train[n])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    trainmat = np.zeros((5, 5), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_train)):\n",
    "            output = model(X_train[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_train[n]).sum().item()\n",
    "            trainmat[y_train[n].item()][y_pred.item()] += 1\n",
    "    print('Train accuracy:', correct / len(y_train))\n",
    "    print(trainmat)\n",
    "    testmat = np.zeros((5, 5), dtype=np.int32)  # Change params\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for n in range(len(X_test)):\n",
    "            output = model(X_test[n])\n",
    "            y_pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(y_test[n]).sum().item()\n",
    "            testmat[y_test[n].item()][y_pred.item()] += 1\n",
    "    print('Test accuracy:', correct / len(y_test))\n",
    "    print(testmat)\n",
    "    acc.append(correct / len(y_test))\n",
    "    print('Time:', time.time() - byrjun)\n",
    "    print('----')\n",
    "print('Mean test accuracy:', np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf14faa-e69d-4058-baea-431545e87b73",
   "metadata": {},
   "source": [
    "Eftir 2 lotur spáir líkanið rétta flokkin fyrir 45% myndanna. Prósentið lækkar á eftir, líklega vegna ofurþjálfunar (\"over-fitting\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48b8b0-cbb6-40d7-ad94-3f77a68bd765",
   "metadata": {},
   "source": [
    "## Lokaorð\n",
    "\n",
    "Hvernig notum við líkan eins og þetta?\n",
    "- Til að greina þrívíddarmyndir sem notendur teikna.\n",
    "- Sem fyrsta skref í stærra líkani sem teiknir sjálft eftir texta sem notendur skrifa.\n",
    "\n",
    "Vandamál:\n",
    "- **Ekki nóg gögn.** Alvörulíkön nota fleiri en 10.000 mynda til að þjálfast.\n",
    "- Ekki nógir flokkar. Allir flokkar, sérstaklega \"líkamshlutar\", eru mjög fjölbreyttir og alls ekki eins fyrir tölvuna.\n",
    "- Við notum aðeins punkta, ekki línur eða flatir, til að greina.\n",
    "\n",
    "En þetta er það besta fyrir gögnin sem ég var með. Og það tók nóg langan tíma til að þjálfa líkanið; þess vegna þurfum við betri tölvu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
