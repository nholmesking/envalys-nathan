{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970ab42f-e0b5-47e2-bca7-e268dd9acaec",
   "metadata": {},
   "source": [
    "# Notkun gervigreindar fyrir teikningu þrívíddarmynda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c4b5e-f8a0-40e4-9a20-fce177517b49",
   "metadata": {},
   "source": [
    "Nathan HK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d3ccaa-e673-4dcf-9068-325a8d71f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pywikibot\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stl import mesh\n",
    "import time\n",
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "mappa = '/Users/002-nathan/Desktop/Envalys/envalys-nathan/'  # Change this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f14fa6-f58f-4887-b619-09ded63df20d",
   "metadata": {},
   "source": [
    "## Inngangsorð\n",
    "Við ætlum að þjálfa gervigreindarlíkan til að teikna þrívíddarmyndir. Hvernig gerum við það?\n",
    "- Fyrst reyndi ég að nota þrívíddardíla eða \"þríla\" (e. *voxels*). Ég taldi punktana í hverjum þríl, og þjálfaði líkan með tölunum, eins og líkan sem greinir ljósmyndir. GitHub: https://github.com/nholmesking/envalys-nathan/blob/4fd89a1515c1c3623a5b8cdf8c766858c465e451/Nathan%20HK.ipynb\n",
    "  - Vandamál #1: Mac-GPU getur ekki neitt með þrívíddargögnum. Ég þurfti að nota CPU, sem er of hægt.\n",
    "  - Vandamál #2: Hraðinn er $O(n^3)$.\n",
    "  - Vandamál #3: Það var engin klár leið til að fara frá greiningu yfir á teikningu.\n",
    "- Þá reyndi ég að nota líkanið 3DShape2VecSet, sem tekur lista yfir punkta og teinkir myndir sem eru eins og listinn.\n",
    "\n",
    "Tilvísanir:\n",
    "- https://arxiv.org/pdf/2301.11445\n",
    "- https://github.com/1zb/3DShape2VecSet\n",
    "\n",
    "Ég gerði litlar breytingar á upprunaforritið, því það er eitt forritasafn (e. *module*) sem virkar ekki lengur, og forritið var skrifað fyrir Windows (og ég nota Mac)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5a80b-f925-4de4-a0cb-4ecfbdd55f23",
   "metadata": {},
   "source": [
    "## Gögn\n",
    "Gögnin frá 3DShape2VecSet eru 650 GB samtals; þetta er of mikið fyrir tölvuna mína.\n",
    "\n",
    "Þessi gögn eru STL-skrár frá Wikimedia Commons. Það eru fimm flokkar:\n",
    "- líkamshlutar\n",
    "- byggingar\n",
    "- rúmfræði\n",
    "- geimfarartæki\n",
    "- styttur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a48e65-ff71-4dff-95a0-621dea4d722a",
   "metadata": {},
   "source": [
    "### Sækja gögn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a80470d-2fe8-4a13-8c49-07d5253f0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "flokkar = ['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
    "skrar = {}\n",
    "catnum = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadeeb0f-d6b6-4bdf-9fba-2979297056b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body parts\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "buildings\n",
      "0\n",
      "10\n",
      "20\n",
      "geometric shapes\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "objects in space\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "sculptures\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "commons = pywikibot.Site('commons', 'commons')\n",
    "cn = 0\n",
    "for a in flokkar:\n",
    "    print(a)\n",
    "    cat = pywikibot.Category(commons, 'STL files of ' + a)\n",
    "    catnum[a] = cn\n",
    "    cn += 1\n",
    "    n = 0\n",
    "    for p in cat.members(member_type=['file']):\n",
    "        if n % 10 == 0:\n",
    "            print(n)\n",
    "        mynd = pywikibot.FilePage(p)\n",
    "        try:\n",
    "            tempf = open(mappa + 'STLdata/' + a + '_' + p.title()[5:], 'r')\n",
    "            tempf.close()\n",
    "        except FileNotFoundError:\n",
    "            mynd.download(filename=mappa + 'STLdata/' + a + '_' + p.title()[5:])\n",
    "        try:\n",
    "            skrar[a].append(p.title()[5:])\n",
    "        except KeyError:\n",
    "            skrar[a] = [p.title()[5:]]\n",
    "        n += 1\n",
    "        if n >= 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af781434-8e30-4444-a693-c601f559cbbe",
   "metadata": {},
   "source": [
    "### Setja upp gögn fyrir notkun\n",
    "Við eigum að breyta gögnunum úr STL-sniði í sniðið sem 3DShape2VecSet notar. Þetta snið er með lista yfir punkta eftir hvort þeir séu innan á forminu eða utan, en gögnin frá Wikimedia Commons er ekki með það.\n",
    "\n",
    "Með ```isInside()``` getum útreiknað hvort lína og þríhyrningur mætast, og í hvora átt. Við búum til tvær línur sem fara beint í X-, Y-, eða Z-áttina frá punktnum (eina línu upp og eina línu niður), og teljum þríhyrningana sem línan mætir; ef talan er slétt, þá er punkturinn utan á forminu, og ef talan er oddatala, þá er punkturinn innan. En það tekur of langan tíma; sumar myndir eru með fleiri en milljón þríhyrninga. \n",
    "\n",
    "Þess vegna bjó ég til þetta reknirit: Við deilum myndinni í 32x32 eða fleiri ílát í þrem ílátahópum, einum fyrir hverja vídd, eftir hnitum hinna vídda. Í byrjun setjum við alla þríhyrninga í þeirra ílát; sumir þríhyrningar, sem eru á línunni milli íláta, eru settir í tvö eða fleiri ílát. Fyrir hvern listapunkt eigum við bara að leita í rétta ílátinu, í hópnum þar sem þríhyrningafjöldinn er lægstur.\n",
    "\n",
    "Með þessu reikniriti (og litlum öðrum breytingum) er sniðbreytingin **400** sinnum fljótari en hún var þegar ég byrjaði. Ég skrifaði sjálfur allt hérna nema ```isInside()```; sjáðu kóðann fyrir tilvísun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b15d8638-2cec-4be6-a409-1dd59801aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInBB(a, randpoint, att):\n",
    "    if att == 'x':\n",
    "        if (a[1] > randpoint[1] and a[4] > randpoint[1] and a[7] > randpoint[1]):\n",
    "            return False\n",
    "        if (a[1] < randpoint[1] and a[4] < randpoint[1] and a[7] < randpoint[1]):\n",
    "            return False\n",
    "        if (a[2] > randpoint[2] and a[5] > randpoint[2] and a[8] > randpoint[2]):\n",
    "            return False\n",
    "        if (a[2] < randpoint[2] and a[5] < randpoint[2] and a[8] < randpoint[2]):\n",
    "            return False\n",
    "        return True\n",
    "    elif att == 'y':\n",
    "        if (a[0] > randpoint[0] and a[3] > randpoint[0] and a[6] > randpoint[0]):\n",
    "            return False\n",
    "        if (a[0] < randpoint[0] and a[3] < randpoint[0] and a[6] < randpoint[0]):\n",
    "            return False\n",
    "        if (a[2] > randpoint[2] and a[5] > randpoint[2] and a[8] > randpoint[2]):\n",
    "            return False\n",
    "        if (a[2] < randpoint[2] and a[5] < randpoint[2] and a[8] < randpoint[2]):\n",
    "            return False\n",
    "        return True\n",
    "    elif att == 'z':\n",
    "        if (a[0] > randpoint[0] and a[3] > randpoint[0] and a[6] > randpoint[0]):\n",
    "            return False\n",
    "        if (a[0] < randpoint[0] and a[3] < randpoint[0] and a[6] < randpoint[0]):\n",
    "            return False\n",
    "        if (a[1] > randpoint[1] and a[4] > randpoint[1] and a[7] > randpoint[1]):\n",
    "            return False\n",
    "        if (a[1] < randpoint[1] and a[4] < randpoint[1] and a[7] < randpoint[1]):\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c34fb2d-668f-4462-9d95-6a7d6dcc3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInside(a, n_, randpoint, att):\n",
    "    if not np.any(n_):\n",
    "        return 0\n",
    " \n",
    "    # This part is from https://diegoinacio.github.io/creative-coding-notebooks-page/pages/ray-intersection_triangle.html\n",
    "    if att == 'x':\n",
    "        e = np.array([1, 0, 0])     # Ray direction\n",
    "    elif att == 'y':\n",
    "        e = np.array([0, 1, 0])     # Ray direction\n",
    "    elif att == 'z':\n",
    "        e = np.array([0, 0, 1])     # Ray direction\n",
    "    if not np.any(np.dot(n_, e)):\n",
    "        return 0\n",
    "    d = - np.dot(n_, a[0:3])\n",
    "    # Finding parameter t\n",
    "    t = - (np.dot(n_, randpoint) + d)/np.dot(n_, e)\n",
    "    P = randpoint + t*e\n",
    "    # Get the resulting vector for each vertex\n",
    "    # following the construction order\n",
    "    Pa = np.dot(np.cross(a[3:6] - a[0:3], P - a[0:3]), n_)\n",
    "    Pb = np.dot(np.cross(a[6:9] - a[3:6], P - a[3:6]), n_)\n",
    "    Pc = np.dot(np.cross(a[0:3] - a[6:9], P - a[6:9]), n_)\n",
    "\n",
    "    if t > 0 and (Pa > 0 and Pb > 0 and Pc > 0):\n",
    "        return 1\n",
    "        \n",
    "    if att == 'x':\n",
    "        e = np.array([-1, 0, 0])     # Ray direction\n",
    "    elif att == 'y':\n",
    "        e = np.array([0, -1, 0])     # Ray direction\n",
    "    elif att == 'z':\n",
    "        e = np.array([0, 0, -1])     # Ray direction\n",
    "    # Finding parameter t\n",
    "    t = - (np.dot(n_, randpoint) + d)/np.dot(n_, e)\n",
    "    P = randpoint + t*e\n",
    "    # Get the resulting vector for each vertex\n",
    "    # following the construction order\n",
    "    Pa = np.dot(np.cross(a[3:6] - a[0:3], P - a[0:3]), n_)\n",
    "    Pb = np.dot(np.cross(a[6:9] - a[3:6], P - a[3:6]), n_)\n",
    "    Pc = np.dot(np.cross(a[0:3] - a[6:9], P - a[6:9]), n_)\n",
    "\n",
    "    if t > 0 and (Pa > 0 and Pb > 0 and Pc > 0):\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75d3ca54-fe85-4887-acee-34c63f178246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body parts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/002-nathan/Desktop/Envalys/envalys-nathan/3DShape2VecSet/data/ShapeNetV2_point/body parts: File exists\n",
      "mkdir: /Users/002-nathan/Desktop/Envalys/envalys-nathan/3DShape2VecSet/data/ShapeNetV2_watertight/body parts: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Vh-f-mammary-gland-r.stl\n",
      "585330\n",
      "train vol 8.585448265075684\n",
      "train near 23.77039098739624\n",
      "Dödsmask av Ivar Arosenius NMSk2348b - Nationalmuseum -3724438ee23c4defadf93d833e8c870d.stl\n",
      "60000\n",
      "train vol 25.43987202644348\n",
      "train near 28.31662106513977\n",
      "We Are Beautiful – 554268-FSAN-1 – solid.stl\n",
      "423450\n",
      "train vol 34.15127396583557\n",
      "train near 38.57626533508301\n",
      "We Are Beautiful – 507391-OSNN-1 – surface.stl\n",
      "107777\n",
      "train vol 40.4840202331543\n",
      "train near 42.263286113739014\n",
      "We Are Beautiful – 591522-FSAN-1 – solid.stl\n",
      "592592\n",
      "train vol 50.02584719657898\n",
      "train near 54.94574213027954\n",
      "Vh-f-liver.stl\n",
      "93303\n",
      "train vol 58.68580603599548\n",
      "train near 64.9116883277893\n",
      "We Are Beautiful – 768772-LSNN-1 – surface.stl\n",
      "478890\n",
      "train vol 71.39727830886841\n",
      "train near 75.35963320732117\n",
      "Vh-m-kidney-r.stl\n",
      "84088\n",
      "train vol 80.26779794692993\n",
      "train near 92.39732503890991\n",
      "3D ear.stl\n",
      "222732\n",
      "train vol 96.33809208869934\n",
      "train near 100.2714192867279\n",
      "Vh-f-ovary-l.stl\n",
      "424\n",
      "train vol 101.13611125946045\n",
      "train near 102.90333008766174\n",
      "We Are Beautiful – 591522-FSAN-4 – solid.stl\n",
      "414088\n",
      "train vol 109.12995409965515\n",
      "train near 113.46301531791687\n",
      "F lymph node left.stl\n",
      "254663\n",
      "train vol 122.691965341568\n",
      "train near 140.36828207969666\n",
      "Vh-m-lung.stl\n",
      "224765\n",
      "train vol 145.16041111946106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 144\u001b[0m\n\u001b[1;32m    142\u001b[0m     n_ \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(n) \u001b[38;5;66;03m# Normalized normal\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     n_dat[h] \u001b[38;5;241m=\u001b[39m n_\n\u001b[0;32m--> 144\u001b[0m isi \u001b[38;5;241m=\u001b[39m \u001b[43misInside\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgogn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_dat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isi \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    146\u001b[0m     pct[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[53], line 21\u001b[0m, in \u001b[0;36misInside\u001b[0;34m(a, n_, randpoint, att)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Get the resulting vector for each vertex\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# following the construction order\u001b[39;00m\n\u001b[1;32m     20\u001b[0m Pa \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mcross(a[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m-\u001b[39m a[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m], P \u001b[38;5;241m-\u001b[39m a[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]), n_)\n\u001b[0;32m---> 21\u001b[0m Pb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, n_)\n\u001b[1;32m     22\u001b[0m Pc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mcross(a[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m a[\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m9\u001b[39m], P \u001b[38;5;241m-\u001b[39m a[\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m9\u001b[39m]), n_)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (Pa \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Pb \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Pc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/numeric.py:1591\u001b[0m, in \u001b[0;36mcross\u001b[0;34m(a, b, axisa, axisb, axisc, axis)\u001b[0m\n\u001b[1;32m   1588\u001b[0m axisb \u001b[38;5;241m=\u001b[39m normalize_axis_index(axisb, b\u001b[38;5;241m.\u001b[39mndim, msg_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxisb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;66;03m# Move working axis to the end of the shape\u001b[39;00m\n\u001b[0;32m-> 1591\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mmoveaxis\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxisa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1592\u001b[0m b \u001b[38;5;241m=\u001b[39m moveaxis(b, axisb, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1593\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible dimensions for cross product\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1594\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(dimension must be 2 or 3)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/numeric.py:1449\u001b[0m, in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1446\u001b[0m     a \u001b[38;5;241m=\u001b[39m asarray(a)\n\u001b[1;32m   1447\u001b[0m     transpose \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose\n\u001b[0;32m-> 1449\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_axis_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m destination \u001b[38;5;241m=\u001b[39m normalize_axis_tuple(destination, a\u001b[38;5;241m.\u001b[39mndim, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(source) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(destination):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([normalize_axis_index(ax, ndim, argname) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([normalize_axis_index(ax, ndim, argname) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cat in skrar:\n",
    "    tts = []\n",
    "    print(cat)\n",
    "    byrjun = time.time()\n",
    "    os.system('mkdir \"' + mappa + '3DShape2VecSet/data/ShapeNetV2_point/' + cat + '\"')\n",
    "    os.system('mkdir \"' + mappa + '3DShape2VecSet/data/ShapeNetV2_watertight/' + cat + '\"')\n",
    "    for fi in skrar[cat]:\n",
    "        gogn = mesh.Mesh.from_file(mappa + 'STLdata/' + cat + '_' + fi)\n",
    "        utskra_mesh = open(mappa + '3DShape2VecSet/data/ShapeNetV2_watertight/' + cat + '/' + fi + '.npz', 'wb')\n",
    "        np.savez(utskra_mesh, points=np.array(gogn.v0, dtype=np.float32), scale=1)\n",
    "        tts.append(fi)\n",
    "    train, val = train_test_split(tts)\n",
    "    trainlst = open(mappa + '3DShape2VecSet/data/ShapeNetV2_point/' + cat + '/train.lst', 'w')\n",
    "    print('train')\n",
    "    for fi in train:\n",
    "        print(fi)\n",
    "        gogn = mesh.Mesh.from_file(mappa + 'STLdata/' + cat + '_' + fi)\n",
    "        print(gogn.points.shape[0])\n",
    "        afora = ([a[0] for a in gogn.v0], [a[1] for a in gogn.v0], [a[2] for a in gogn.v0])\n",
    "        mm = ((min(afora[0]), max(afora[0])),\n",
    "              (min(afora[1]), max(afora[1])),\n",
    "              (min(afora[2]), max(afora[2])))\n",
    "        num_ilat = max(32, int((gogn.points.shape[0] / 500) ** (1/2)))\n",
    "        ilat_X = []\n",
    "        for i in range(num_ilat):\n",
    "            ilat_X.append([])\n",
    "            for j in range(num_ilat):\n",
    "                ilat_X[i].append([])\n",
    "        ilat_Y = []\n",
    "        for i in range(num_ilat):\n",
    "            ilat_Y.append([])\n",
    "            for j in range(num_ilat):\n",
    "                ilat_Y[i].append([])\n",
    "        ilat_Z = []\n",
    "        for i in range(num_ilat):\n",
    "            ilat_Z.append([])\n",
    "            for j in range(num_ilat):\n",
    "                ilat_Z[i].append([])\n",
    "        nyfirm = (num_ilat / (mm[0][1] - mm[0][0]), num_ilat / (mm[1][1] - mm[1][0]), num_ilat / (mm[2][1] - mm[2][0]))\n",
    "        ilatid = lambda x, y, z: (max(0, min(int((x - mm[0][0]) * nyfirm[0]), num_ilat - 1)),\n",
    "                                  max(0, min(int((y - mm[1][0]) * nyfirm[1]), num_ilat - 1)),\n",
    "                                  max(0, min(int((z - mm[2][0]) * nyfirm[2]), num_ilat - 1)))\n",
    "        utskra = open(mappa + '3DShape2VecSet/data/ShapeNetV2_point/' + cat + '/' + fi + '.npz', 'wb')\n",
    "        vol_points = []\n",
    "        vol_label = []\n",
    "        for h in range(gogn.points.shape[0]):\n",
    "            a = gogn.points[h]\n",
    "            minid = ilatid(min(a[0], a[3], a[6]), min(a[1], a[4], a[7]), min(a[2], a[5], a[8]))\n",
    "            maxid = ilatid(max(a[0], a[3], a[6]), max(a[1], a[4], a[7]), max(a[2], a[5], a[8]))\n",
    "            for i in range(minid[0], maxid[0] + 1):\n",
    "                for j in range(minid[1], maxid[1] + 1):\n",
    "                    ilat_Z[i][j].append(h)\n",
    "            for i in range(minid[0], maxid[0] + 1):\n",
    "                for k in range(minid[2], maxid[2] + 1):\n",
    "                    ilat_Y[i][k].append(h)\n",
    "            for j in range(minid[1], maxid[1] + 1):\n",
    "                for k in range(minid[2], maxid[2] + 1):\n",
    "                    ilat_X[j][k].append(h)\n",
    "        n_dat = {}\n",
    "        for i in range(4096):\n",
    "            randpoint = (np.random.uniform(mm[0][0], mm[0][1]),\n",
    "                         np.random.uniform(mm[1][0], mm[1][1]),\n",
    "                         np.random.uniform(mm[2][0], mm[2][1]))\n",
    "            # Is point inside or outside shape?\n",
    "            fata = ilatid(randpoint[0], randpoint[1], randpoint[2])\n",
    "            pct = [0, 0]\n",
    "            if len(ilat_X[fata[1]][fata[2]]) <= min(len(ilat_Y[fata[0]][fata[2]]), len(ilat_Z[fata[0]][fata[1]])):\n",
    "                for h in ilat_X[fata[1]][fata[2]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'x'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'x')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            elif len(ilat_Y[fata[0]][fata[2]]) <= min(len(ilat_X[fata[1]][fata[2]]), len(ilat_Z[fata[0]][fata[1]])):\n",
    "                for h in ilat_Y[fata[0]][fata[2]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'y'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'y')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            elif len(ilat_Z[fata[0]][fata[1]]) <= min(len(ilat_X[fata[1]][fata[2]]), len(ilat_Y[fata[0]][fata[2]])):\n",
    "                for h in ilat_Z[fata[0]][fata[1]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'z'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'z')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            if len(pct) == 2 and pct[0] % 2 == pct[1] % 2:\n",
    "                vol_points.append(randpoint)\n",
    "                vol_label.append(pct[0] % 2)\n",
    "        print('train vol', time.time() - byrjun)\n",
    "        near_points = []\n",
    "        near_label = []\n",
    "        for i in range(4096):\n",
    "            gp = gogn.points[np.random.randint(0, gogn.points.shape[0])]\n",
    "            randpoint = (gp[0] + np.random.uniform(mm[0][0] / 100, mm[0][1] / 100),\n",
    "                         gp[1] + np.random.uniform(mm[1][0] / 100, mm[1][1] / 100),\n",
    "                         gp[2] + np.random.uniform(mm[2][0] / 100, mm[2][1] / 100))\n",
    "            # Is point inside or outside shape?\n",
    "            fata = ilatid(randpoint[0], randpoint[1], randpoint[2])\n",
    "            pct = [0, 0]\n",
    "            if len(ilat_X[fata[1]][fata[2]]) <= min(len(ilat_Y[fata[0]][fata[2]]), len(ilat_Z[fata[0]][fata[1]])):\n",
    "                for h in ilat_X[fata[1]][fata[2]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'x'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'x')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            elif len(ilat_Y[fata[0]][fata[2]]) <= min(len(ilat_X[fata[1]][fata[2]]), len(ilat_Z[fata[0]][fata[1]])):\n",
    "                for h in ilat_Y[fata[0]][fata[2]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'y'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'y')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            elif len(ilat_Z[fata[0]][fata[1]]) <= min(len(ilat_X[fata[1]][fata[2]]), len(ilat_Y[fata[0]][fata[2]])):\n",
    "                for h in ilat_Z[fata[0]][fata[1]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'z'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'z')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            if len(pct) == 2 and pct[0] % 2 == pct[1] % 2:\n",
    "                near_points.append(randpoint)\n",
    "                near_label.append(pct[0] % 2)\n",
    "        print('train near', time.time() - byrjun)\n",
    "        if len(vol_points) > 0 and len(near_points) > 0:\n",
    "            trainlst.write(fi + '.npz\\n')\n",
    "            np.savez(utskra,\n",
    "                     vol_points=np.array(vol_points, dtype=np.float32),\n",
    "                     vol_label=np.array(vol_label),\n",
    "                     near_points=np.array(near_points, dtype=np.float32),\n",
    "                     near_label=np.array(near_label))\n",
    "    trainlst.close()\n",
    "    vallst = open(mappa + '3DShape2VecSet/data/ShapeNetV2_point/' + cat + '/val.lst', 'w')\n",
    "    print('val')\n",
    "    for fi in val:\n",
    "        print(fi)\n",
    "        vallst.write(fi + '.npz\\n')\n",
    "        gogn = mesh.Mesh.from_file(mappa + 'STLdata/' + cat + '_' + fi)\n",
    "        print(gogn.points.shape[0])\n",
    "        mm = ((min([a[0] for a in gogn.v0]), max([a[0] for a in gogn.v0])),\n",
    "              (min([a[1] for a in gogn.v0]), max([a[1] for a in gogn.v0])),\n",
    "              (min([a[2] for a in gogn.v0]), max([a[2] for a in gogn.v0])))\n",
    "        num_ilat = max(32, int((gogn.points.shape[0] / 500) ** (1/2)))\n",
    "        ilat_X = []\n",
    "        for i in range(num_ilat):\n",
    "            ilat_X.append([])\n",
    "            for j in range(num_ilat):\n",
    "                ilat_X[i].append([])\n",
    "        ilat_Y = []\n",
    "        for i in range(num_ilat):\n",
    "            ilat_Y.append([])\n",
    "            for j in range(num_ilat):\n",
    "                ilat_Y[i].append([])\n",
    "        ilat_Z = []\n",
    "        for i in range(num_ilat):\n",
    "            ilat_Z.append([])\n",
    "            for j in range(num_ilat):\n",
    "                ilat_Z[i].append([])\n",
    "        nyfirm = (num_ilat / (mm[0][1] - mm[0][0]), num_ilat / (mm[1][1] - mm[1][0]), num_ilat / (mm[2][1] - mm[2][0]))\n",
    "        ilatid = lambda x, y, z: (max(0, min(int((x - mm[0][0]) * nyfirm[0]), num_ilat - 1)),\n",
    "                                  max(0, min(int((y - mm[1][0]) * nyfirm[1]), num_ilat - 1)),\n",
    "                                  max(0, min(int((z - mm[2][0]) * nyfirm[2]), num_ilat - 1)))\n",
    "        utskra = open(mappa + '3DShape2VecSet/data/ShapeNetV2_point/' + cat + '/' + fi + '.npz', 'wb')\n",
    "        vol_points = []\n",
    "        vol_label = []\n",
    "        for h in range(gogn.points.shape[0]):\n",
    "            a = gogn.points[h]\n",
    "            minid = ilatid(min(a[0], a[3], a[6]), min(a[1], a[4], a[7]), min(a[2], a[5], a[8]))\n",
    "            maxid = ilatid(max(a[0], a[3], a[6]), max(a[1], a[4], a[7]), max(a[2], a[5], a[8]))\n",
    "            for i in range(minid[0], maxid[0] + 1):\n",
    "                for j in range(minid[1], maxid[1] + 1):\n",
    "                    ilat_Z[i][j].append(h)\n",
    "            for i in range(minid[0], maxid[0] + 1):\n",
    "                for k in range(minid[2], maxid[2] + 1):\n",
    "                    ilat_Y[i][k].append(h)\n",
    "            for j in range(minid[1], maxid[1] + 1):\n",
    "                for k in range(minid[2], maxid[2] + 1):\n",
    "                    ilat_X[j][k].append(h)\n",
    "        n_dat = {}\n",
    "        for i in range(4096):\n",
    "            randpoint = (np.random.uniform(mm[0][0], mm[0][1]),\n",
    "                         np.random.uniform(mm[1][0], mm[1][1]),\n",
    "                         np.random.uniform(mm[2][0], mm[2][1]))\n",
    "            # Is point inside or outside shape?\n",
    "            fata = ilatid(randpoint[0], randpoint[1], randpoint[2])\n",
    "            pct = [0, 0]\n",
    "            if len(ilat_X[fata[1]][fata[2]]) <= min(len(ilat_Y[fata[0]][fata[2]]), len(ilat_Z[fata[0]][fata[1]])):\n",
    "                for h in ilat_X[fata[1]][fata[2]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'x'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'x')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            elif len(ilat_Y[fata[0]][fata[2]]) <= min(len(ilat_X[fata[1]][fata[2]]), len(ilat_Z[fata[0]][fata[1]])):\n",
    "                for h in ilat_Y[fata[0]][fata[2]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'y'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'y')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            elif len(ilat_Z[fata[0]][fata[1]]) <= min(len(ilat_X[fata[1]][fata[2]]), len(ilat_Y[fata[0]][fata[2]])):\n",
    "                for h in ilat_Z[fata[0]][fata[1]]:\n",
    "                    if isInBB(gogn.points[h], randpoint, 'z'):\n",
    "                        try:\n",
    "                            n_dat[h]\n",
    "                        except KeyError:\n",
    "                            a = gogn.points[h]\n",
    "                            AB = a[3:6] - a[0:3]               # Oriented segment A to B\n",
    "                            AC = a[6:9] - a[0:3]               # Oriented segment A to C\n",
    "                            n = np.cross(AB, AC)     # Normal vector\n",
    "                            n_ = n/np.linalg.norm(n) # Normalized normal\n",
    "                            n_dat[h] = n_\n",
    "                        isi = isInside(gogn.points[h], n_dat[h], randpoint, 'z')\n",
    "                        if isi == 1:\n",
    "                            pct[1] += 1\n",
    "                        elif isi == -1:\n",
    "                            pct[0] += 1\n",
    "            if len(pct) == 2 and pct[0] % 2 == pct[1] % 2:\n",
    "                vol_points.append(randpoint)\n",
    "                vol_label.append(pct[0] % 2)\n",
    "        if len(vol_points) > 0:\n",
    "            print('val vol', time.time() - byrjun)\n",
    "            np.savez(utskra,\n",
    "                     vol_points=np.array(vol_points, dtype=np.float32),\n",
    "                     vol_label=np.array(vol_label))\n",
    "    vallst.close()\n",
    "    print(time.time() - byrjun)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bb9b9-bf1e-498e-be31-ee3b360ce2f0",
   "metadata": {},
   "source": [
    "Sniðbreytingin tók 28 mínútur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2e0e5-6430-4a8a-8abe-2447a02233e9",
   "metadata": {},
   "source": [
    "## Líkan\n",
    "Líkanið þarf ekki að búa til góðar myndir. Það þarf bara að virka án villna, sem sýnir okkur að við þurfum bara meiri og betri gögn, því vísindagreinin er með góðar myndir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b091fd08-7450-4ff4-b14c-e5aa888d7d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 09:05:21.680789 8286703424 torch/distributed/elastic/multiprocessing/redirects.py:28] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0825 09:05:21.693071 8286703424 torch/distributed/run.py:779] \n",
      "W0825 09:05:21.693071 8286703424 torch/distributed/run.py:779] *****************************************\n",
      "W0825 09:05:21.693071 8286703424 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0825 09:05:21.693071 8286703424 torch/distributed/run.py:779] *****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "\n",
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "['body parts', 'buildings', 'geometric shapes', 'objects in space', 'sculptures']\n",
      "Model = AutoEncoder(\n",
      "  (cross_attend_blocks): ModuleList(\n",
      "    (0): PreNorm(\n",
      "      (fn): Attention(\n",
      "        (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): PreNorm(\n",
      "      (fn): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "          (1): GEGLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (point_embed): PointEmbed(\n",
      "    (mlp): Linear(in_features=51, out_features=512, bias=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-23): 24 x ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_cross_attn): PreNorm(\n",
      "    (fn): Attention(\n",
      "      (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (to_outputs): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "number of params (M): 106.12\n",
      "base lr: 1.00e-04\n",
      "actual lr: 5.00e-05\n",
      "accumulate grad iterations: 2\n",
      "effective batch size: 128\n",
      "criterion = BCEWithLogitsLoss()\n",
      "Start training for 200 epochs\n",
      "log_dir: output/ae/ae_d512_m512\n",
      "Model = AutoEncoder(\n",
      "  (cross_attend_blocks): ModuleList(\n",
      "    (0): PreNorm(\n",
      "      (fn): Attention(\n",
      "        (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): PreNorm(\n",
      "      (fn): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "          (1): GEGLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (point_embed): PointEmbed(\n",
      "    (mlp): Linear(in_features=51, out_features=512, bias=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-23): 24 x ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_cross_attn): PreNorm(\n",
      "    (fn): Attention(\n",
      "      (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (to_outputs): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "number of params (M): 106.12\n",
      "base lr: 1.00e-04\n",
      "actual lr: 5.00e-05\n",
      "accumulate grad iterations: 2\n",
      "effective batch size: 128\n",
      "criterion = BCEWithLogitsLoss()\n",
      "Start training for 200 epochs\n",
      "log_dir: output/ae/ae_d512_m512\n",
      "Model = AutoEncoder(\n",
      "  (cross_attend_blocks): ModuleList(\n",
      "    (0): PreNorm(\n",
      "      (fn): Attention(\n",
      "        (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): PreNorm(\n",
      "      (fn): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "          (1): GEGLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (point_embed): PointEmbed(\n",
      "    (mlp): Linear(in_features=51, out_features=512, bias=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-23): 24 x ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_cross_attn): PreNorm(\n",
      "    (fn): Attention(\n",
      "      (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (to_outputs): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "number of params (M): 106.12\n",
      "base lr: 1.00e-04\n",
      "actual lr: 5.00e-05\n",
      "accumulate grad iterations: 2\n",
      "effective batch size: 128\n",
      "criterion = BCEWithLogitsLoss()\n",
      "Start training for 200 epochs\n",
      "log_dir: output/ae/ae_d512_m512\n",
      "Model = AutoEncoder(\n",
      "  (cross_attend_blocks): ModuleList(\n",
      "    (0): PreNorm(\n",
      "      (fn): Attention(\n",
      "        (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): PreNorm(\n",
      "      (fn): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "          (1): GEGLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (point_embed): PointEmbed(\n",
      "    (mlp): Linear(in_features=51, out_features=512, bias=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0-23): 24 x ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_cross_attn): PreNorm(\n",
      "    (fn): Attention(\n",
      "      (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
      "      (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (drop_path): Identity()\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm_context): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (to_outputs): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "number of params (M): 106.12\n",
      "base lr: 1.00e-04\n",
      "actual lr: 5.00e-05\n",
      "accumulate grad iterations: 2\n",
      "effective batch size: 128\n",
      "criterion = BCEWithLogitsLoss()\n",
      "Start training for 200 epochs\n",
      "log_dir: output/ae/ae_d512_m512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/47]  eta: 0:43:45  lr: 0.000000  loss: 0.7250 (0.7250)  loss_vol: 0.6592 (0.6592)  loss_near: 0.6580 (0.6580)  iou: 0.0139 (0.0139)  time: 55.8586  data: 19.8939\n",
      "Epoch: [0]  [ 0/47]  eta: 0:49:22  lr: 0.000000  loss: 0.7185 (0.7185)  loss_vol: 0.6532 (0.6532)  loss_near: 0.6534 (0.6534)  iou: 0.0089 (0.0089)  time: 63.0310  data: 19.9302\n",
      "Epoch: [0]  [ 0/47]  eta: 0:50:54  lr: 0.000000  loss: 0.7204 (0.7204)  loss_vol: 0.6549 (0.6549)  loss_near: 0.6550 (0.6550)  iou: 0.0234 (0.0234)  time: 64.9863  data: 16.6555\n",
      "Epoch: [0]  [ 0/47]  eta: 1:23:32  lr: 0.000000  loss: 0.7272 (0.7272)  loss_vol: 0.6611 (0.6611)  loss_near: 0.6610 (0.6610)  iou: 0.0238 (0.0238)  time: 106.6386  data: 16.7561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 09:35:12.375863 8286703424 torch/distributed/elastic/agent/server/api.py:688] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0825 09:35:12.392325 8286703424 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 40348 closing signal SIGINT\n",
      "W0825 09:35:12.393383 8286703424 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 40349 closing signal SIGINT\n",
      "W0825 09:35:12.393764 8286703424 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 40350 closing signal SIGINT\n",
      "W0825 09:35:12.398679 8286703424 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 40351 closing signal SIGINT\n",
      "W0825 09:35:42.408644 8286703424 torch/distributed/elastic/multiprocessing/api.py:875] Unable to shutdown process 40348 via Signals.SIGINT, forcefully exiting via Signals.SIGKILL\n",
      "W0825 09:35:49.303166 8286703424 torch/distributed/elastic/multiprocessing/api.py:875] Unable to shutdown process 40349 via Signals.SIGINT, forcefully exiting via Signals.SIGKILL\n",
      "W0825 09:35:53.514046 8286703424 torch/distributed/elastic/multiprocessing/api.py:875] Unable to shutdown process 40350 via Signals.SIGINT, forcefully exiting via Signals.SIGKILL\n",
      "W0825 09:35:53.717976 8286703424 torch/distributed/elastic/multiprocessing/api.py:875] Unable to shutdown process 40351 via Signals.SIGINT, forcefully exiting via Signals.SIGKILL\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 255, in launch_agent\n",
      "    result = agent.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 124, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 680, in run\n",
      "    result = self._invoke_run(role)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 835, in _invoke_run\n",
      "    time.sleep(monitor_interval)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 79, in _terminate_process_handler\n",
      "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
      "torch.distributed.elastic.multiprocessing.api.SignalException: Process 40347 got signal: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('cd ' + mappa)\n",
    "os.system('torchrun --nproc_per_node=4 3DShape2VecSet/main_ae.py --accum_iter=2 --model ae_d512_m512 '\n",
    "          '--data_path 3DShape2VecSet/data --output_dir output/ae/ae_d512_m512 --log_dir output/ae/ae_d512_m512 '\n",
    "          '--num_workers 10 --point_cloud_size 2048 --batch_size 64 --epochs 200 --warmup_epochs 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cc70c-877e-4340-b8f0-ad47d8c4a6b7",
   "metadata": {},
   "source": [
    "Það eru 200 lotna (e. *epochs*), og hver lota tekur klukkustund; við eigum ekki nógan tíma fyrir alla þjálfunina. **En hún er hafin án villna.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041c887-ed3f-49f4-9ba1-79d47821d854",
   "metadata": {},
   "source": [
    "# Lokaorð\n",
    "Hvert förum við héðan? 3DShape2VecSet er með margar takmarkanir.\n",
    "- Það kann bara að búa til einfaldar myndir, eins og \"stóll\". Með greiningarlíkani getum við mögulega búið til fjölfaldar myndir. Ef notandi segir \"stóll með kodda\", þá býr líkanið okkar til mynd af stóli og mynd af kodda, sem líkanið sameinar.\n",
    "- Það skilur ekki mannamál.\n",
    "- Það er ekki með mikil gögn. Með mínu forriti hérna getum við búið til eins mikil gögn og við viljum; við getum tekið myndir frá notendum og búum til lista yfir punkta, og notað þá til að þjálfa líkanið.\n",
    "\n",
    "Ég er viss um að, með meiri gögn og betri tölvu, við getum að minnsta kosti eitt af þessum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
